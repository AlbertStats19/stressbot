{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e64227d",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e16b1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa_stress_test.ipynb\n",
    "\n",
    "# --- 0. Configuración Inicial y Carga de Librerías ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "from openai import OpenAI\n",
    "# Importación de utils asumiendo que está en la misma carpeta 'notebooks/'\n",
    "# Asegúrate de que utils.py contenga la clase TimerResult y el @contextmanager def timer(name): yield result\n",
    "from utils import timer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efd949c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para asegurar que se muestren todas las columnas de Pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c00ea0e",
   "metadata": {},
   "source": [
    "## path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36e89cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>> RUTA BASE PERSONALIZADA DEL PROYECTO (INTEGRACIÓN DE TU pk_) <<<<<\n",
    "# Esta ruta es esencial para que el notebook encuentre los archivos\n",
    "# generados por data_generator.py (data/, company_docs/, etc.)\n",
    "pk_ = \"C:/Users/Alber/OneDrive/Documentos/MADUREZ MLOPS/gerente-relacional-qa-test/\"\n",
    "# Puedes ajustar esta variable si la ubicación de tu proyecto cambia.\n",
    "# >>>>> FIN DE RUTA BASE PERSONALIZADA <<<<<"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e4a8fa",
   "metadata": {},
   "source": [
    "## open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99b1f9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando credenciales de OpenAI...\n",
      "Credenciales cargadas. Cliente OpenAI inicializado.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Cargar Credenciales ---\n",
    "print(\"Cargando credenciales de OpenAI...\")\n",
    "try:\n",
    "    # Usar pk_ para la ruta de credentials.json\n",
    "    with open(os.path.join('credentials.json')) as f:\n",
    "        config_env = json.load(f)\n",
    "    api_key = config_env[\"openai_key\"]\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    print(\"Credenciales cargadas. Cliente OpenAI inicializado.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: 'credentials.json' no encontrado en la ruta: {os.path.join(pk_, 'credentials.json')}. Asegúrate de crearlo en la raíz de tu proyecto ('{pk_}').\")\n",
    "    api_key = None\n",
    "    client = None\n",
    "except KeyError:\n",
    "    print(\"ERROR: 'openai_key' no encontrada en 'credentials.json'.\")\n",
    "    api_key = None\n",
    "    client = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6ec669",
   "metadata": {},
   "source": [
    "## YAML Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c97cfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cargando prompts desde prompts.yml...\n",
      "Prompts de reporte unificado cargados: ['unified_report_1', 'unified_report_2', 'unified_report_3', 'unified_report_4', 'unified_report_5']\n",
      "[TIMER] Carga de prompts y queries: 0.029s\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Cargar Prompts del Reporte Unificado ---\n",
    "print(\"\\nCargando prompts desde prompts.yml...\")\n",
    "# Usar pk_ para la ruta de prompts.yml\n",
    "prompts_path = os.path.join('prompts.yml')\n",
    "unified_report_prompts = {}\n",
    "with timer(\"Carga de prompts y queries\") as t_prompts: # Timer para esta etapa\n",
    "    try:\n",
    "        with open(prompts_path, 'r', encoding='utf-8') as file:\n",
    "            all_prompts = yaml.safe_load(file)\n",
    "        unified_report_prompts = {k: v for k, v in all_prompts.items() if k.startswith('unified_report_')}\n",
    "        print(f\"Prompts de reporte unificado cargados: {list(unified_report_prompts.keys())}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: '{prompts_path}' no encontrado.\")\n",
    "    except yaml.YAMLError as e:\n",
    "        print(f\"ERROR al parsear YAML: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdff580",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "354bb08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cargando datas simuladas...\n",
      "Data de transacciones cargada (LIGHT). Registros: 2000\n",
      "Data financiera cargada (LIGHT). Registros: 1000\n",
      "Mapeo de 25 empresas cargado.\n",
      "[TIMER] Carga de dataframes e historial: 0.029s\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Cargar Datas Simuladas (10M Transacciones y 300K Financieros) y Mapeo de Empresas ---\n",
    "print(\"\\nCargando datas simuladas...\")\n",
    "transactions_df = pd.DataFrame()\n",
    "financial_df = pd.DataFrame()\n",
    "company_mapping = [] # Lista de diccionarios {original_name, sanitized_folder_name}\n",
    "\n",
    "# Decide qué versión de datos cargar (LIGHT o FULL)\n",
    "USE_LIGHT_DATA = True # Cambia a False para usar los datos grandes (10M/300K)\n",
    "\n",
    "transactions_file = 'simulated_transactions.csv'\n",
    "financial_file = 'simulated_financial_metrics.csv'\n",
    "\n",
    "with timer(\"Carga de dataframes e historial\") as t_data_load: # Timer para esta etapa\n",
    "    try:\n",
    "        # Usar pk_ para la ruta de los archivos de datos\n",
    "        transactions_df = pd.read_csv(os.path.join(pk_, 'data', transactions_file))\n",
    "        print(f\"Data de transacciones cargada ({'LIGHT' if USE_LIGHT_DATA else 'FULL'}). Registros: {len(transactions_df)}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: '{transactions_file}' no encontrado en la ruta: '{os.path.join(pk_, 'data')}/'. Ejecuta data_generator.py (o _light.py).\")\n",
    "\n",
    "    try:\n",
    "        # Usar pk_ para la ruta de los archivos de datos\n",
    "        financial_df = pd.read_csv(os.path.join(pk_, 'data', financial_file))\n",
    "        print(f\"Data financiera cargada ({'LIGHT' if USE_LIGHT_DATA else 'FULL'}). Registros: {len(financial_df)}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: '{financial_file}' no encontrado en la ruta: '{os.path.join(pk_, 'data')}/'. Ejecuta data_generator.py (o _light.py).\")\n",
    "\n",
    "    # Cargar el mapeo de empresas\n",
    "    try:\n",
    "        # Usar pk_ para la ruta del mapeo de empresas\n",
    "        with open(os.path.join(pk_, 'data', 'company_mapping.json'), 'r', encoding='utf-8') as f:\n",
    "            company_mapping = json.load(f)\n",
    "        print(f\"Mapeo de {len(company_mapping)} empresas cargado.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: 'company_mapping.json' no encontrado en la ruta: '{os.path.join(pk_, 'data')}/'. Ejecuta data_generator.py (o _light.py).\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"ERROR: Fallo al leer 'company_mapping.json'. Asegúrate de que es un JSON válido.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc5b0b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>date</th>\n",
       "      <th>amount</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Posada-Peña S.A.S.</td>\n",
       "      <td>2024-09-10</td>\n",
       "      <td>586644.59</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>Libero porro quam modi incidunt.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id        company_name        date     amount   type                       description\n",
       "0               0  Posada-Peña S.A.S.  2024-09-10  586644.59  DEBIT  Libero porro quam modi incidunt."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e006b286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>financial_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>year</th>\n",
       "      <th>revenue</th>\n",
       "      <th>profit</th>\n",
       "      <th>liquidity_ratio</th>\n",
       "      <th>debt_equity_ratio</th>\n",
       "      <th>cash_flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Gómez-Cardozo S.A.S.</td>\n",
       "      <td>2021</td>\n",
       "      <td>14103440.43</td>\n",
       "      <td>19772809.19</td>\n",
       "      <td>0.69</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9111115.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   financial_id          company_name  year      revenue       profit  liquidity_ratio  debt_equity_ratio   cash_flow\n",
       "0             0  Gómez-Cardozo S.A.S.  2021  14103440.43  19772809.19             0.69                2.1  9111115.75"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f132cb",
   "metadata": {},
   "source": [
    "## PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de0aba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Función para Cargar Contenido de PDFs Simulados por Empresa ---\n",
    "def load_company_documents(sanitized_folder_name):\n",
    "    \"\"\"Carga el contenido textual simulado de los PDFs para una empresa usando su nombre de carpeta sanitizado.\"\"\"\n",
    "    doc_contents = {}\n",
    "    # Usar pk_ para la ruta base de los documentos de las empresas\n",
    "    base_path = os.path.join(pk_, 'company_docs', sanitized_folder_name)\n",
    "    if not os.path.exists(base_path):\n",
    "        print(f\"Advertencia: Carpeta de documentos no encontrada para '{sanitized_folder_name}' en '{base_path}'\")\n",
    "        return doc_contents\n",
    "\n",
    "    with timer(f\"Carga documentos para {sanitized_folder_name}\") as t_doc_load:\n",
    "        for doc_type in ['gestion', 'sectorial', 'financiero']:\n",
    "            file_path = os.path.join(base_path, f'{doc_type}.txt')\n",
    "            if os.path.exists(file_path):\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    doc_contents[doc_type] = f.read()\n",
    "            else:\n",
    "                doc_contents[doc_type] = \"\" # Vacío si no se encuentra el archivo\n",
    "    return doc_contents\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec3d61a",
   "metadata": {},
   "source": [
    "## FLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13cdd0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Lógica Principal de Generación de Reporte (Emulación del main.py) ---\n",
    "\n",
    "def run_unified_report_flow(company_original_name, company_sanitized_folder_name, report_prompt_key, user_query=\"\"):\n",
    "    \"\"\"\n",
    "    Ejecuta un flujo simulado de generación de reporte unificado para una empresa.\n",
    "    Mide tiempos y recolecta métricas.\n",
    "    \"\"\"\n",
    "    if client is None or not unified_report_prompts or not company_mapping:\n",
    "        print(\"ERROR: Cliente OpenAI no inicializado, prompts no cargados o mapeo de empresas ausente. Abortando.\")\n",
    "        return {\"status\": \"failed\", \"error\": \"Setup incomplete\"}\n",
    "\n",
    "    print(f\"\\n--- Ejecutando flujo para {company_original_name} ({report_prompt_key}) ---\")\n",
    "    metrics = {\n",
    "        \"status\": \"success\",\n",
    "        \"total_execution_time\": 0.0,\n",
    "        \"llm_input_tokens\": 0,\n",
    "        \"llm_output_tokens\": 0,\n",
    "        \"data_processed_tx_rows\": 0,\n",
    "        \"data_processed_fin_rows\": 0,\n",
    "        \"llm_api_latency\": 0.0, # Latencia de la llamada al LLM aislada\n",
    "        \"timer_metrics\": {} # Para guardar los tiempos de cada [TIMER]\n",
    "    }\n",
    "    \n",
    "    # Timer principal para el flujo completo\n",
    "    with timer(\"Tiempo total conversación\") as total_timer_result: \n",
    "        # --- [TIMER] Normalización y decisión de flujo: (SIMULADO)\n",
    "        with timer(\"Normalización y decisión de flujo\") as t_norm_result:\n",
    "            time.sleep(0.001) # Pequeña simulación de procesamiento\n",
    "            metrics[\"timer_metrics\"][\"Normalización y decisión de flujo\"] = t_norm_result.elapsed_time\n",
    "        \n",
    "        # --- [TIMER] Inicialización cliente e historial: (SIMULADO)\n",
    "        with timer(\"Inicialización cliente e historial\") as t_init_result:\n",
    "            time.sleep(0.01) # Pequeña simulación\n",
    "            metrics[\"timer_metrics\"][\"Inicialización cliente e historial\"] = t_init_result.elapsed_time\n",
    "\n",
    "        # --- [TIMER] Configuración y modelos: (SIMULADO)\n",
    "        with timer(\"Configuración y modelos\") as t_config_result:\n",
    "            time.sleep(0.05) # Simulación de tiempo para configuración\n",
    "            metrics[\"timer_metrics\"][\"Configuración y modelos\"] = t_config_result.elapsed_time\n",
    "        \n",
    "        # --- [TIMER] Creación de PineconeManagers (incluye carga de docs simulada):\n",
    "        with timer(\"Creación de PineconeManagers (carga de documentos)\") as t_pinecone_init_result:\n",
    "            company_docs = load_company_documents(company_sanitized_folder_name)\n",
    "            metrics[\"timer_metrics\"][\"Creación de PineconeManagers (carga de documentos)\"] = t_pinecone_init_result.elapsed_time\n",
    "        \n",
    "        # --- Preparar el Prompt Final para el LLM ---\n",
    "        current_report_prompt_template = unified_report_prompts.get(report_prompt_key)\n",
    "        if not current_report_prompt_template:\n",
    "            print(f\"ERROR: Prompt '{report_prompt_key}' no encontrado.\")\n",
    "            metrics[\"status\"] = \"failed\"\n",
    "            return metrics\n",
    "        \n",
    "        # --- [TIMER] Filtrado de dataframes por empresa (simulando query a BD) ---\n",
    "        with timer(\"Filtrado de dataframes por empresa (simulando query a BD)\") as t_filter_df_result:\n",
    "            company_transactions_df = transactions_df[transactions_df['company_name'] == company_original_name].copy()\n",
    "            company_financial_df = financial_df[financial_df['company_name'] == company_original_name].copy()\n",
    "            metrics[\"data_processed_tx_rows\"] = len(company_transactions_df)\n",
    "            metrics[\"data_processed_fin_rows\"] = len(company_financial_df)\n",
    "            metrics[\"timer_metrics\"][\"Filtrado de dataframes por empresa (simulando query a BD)\"] = t_filter_df_result.elapsed_time\n",
    "\n",
    "        # --- [TIMER] Búsqueda similitud reporte unificado (simulando Pinecone/RAG):\n",
    "        with timer(\"Búsqueda similitud reporte unificado\") as t_rag_search_result:\n",
    "            context_from_docs = company_docs.get('gestion', '') + \"\\n\\n\" + \\\n",
    "                                company_docs.get('sectorial', '') + \"\\n\\n\" + \\\n",
    "                                company_docs.get('financiero', '')\n",
    "            \n",
    "            time.sleep(0.01 + len(context_from_docs) / 1000000.0)\n",
    "            \n",
    "        # >>>>> AÑADE ESTAS LÍNEAS PARA DEPURACIÓN <<<<<\n",
    "        print(f\"DEBUG: Tipo de t_rag_search_result después del bloque timer: {type(t_rag_search_result)}\")\n",
    "        if t_rag_search_result is not None:\n",
    "            print(f\"DEBUG: Valor de t_rag_search_result.elapsed_time: {t_rag_search_result.elapsed_time}\")\n",
    "        else:\n",
    "            print(\"DEBUG: t_rag_search_result es None.\")\n",
    "        # >>>>> FIN DE LÍNEAS DE DEPURACIÓN <<<<<\n",
    "\n",
    "        metrics[\"timer_metrics\"][\"Búsqueda similitud reporte unificado\"] = t_rag_search_result.elapsed_time\n",
    "\n",
    "        # --- Rellenar los placeholders del prompt ---\n",
    "        simulated_products_list = \"Préstamos Comerciales, Créditos de Liquidez, Cuentas de Ahorro, CDT.\"\n",
    "        simulated_sector = \"Tecnología y Servicios Financieros\" \n",
    "\n",
    "        df_desem_pag_cast_md_str = company_transactions_df.head(5).to_markdown(index=False)\n",
    "        df_perfilador_md_str = company_financial_df.head(5).to_markdown(index=False)\n",
    "\n",
    "        response_va_simulated = \"Según Valora Analitik, la empresa ha invertido en IA para optimizar procesos bancarios.\"\n",
    "        response_pp_simulated = \"En Primera Página se destacó la expansión regional de la empresa en el último año.\"\n",
    "\n",
    "        try:\n",
    "            formatted_prompt = current_report_prompt_template.format(\n",
    "                company_name=company_original_name,\n",
    "                user_request=user_query if user_query else f\"Genera un reporte unificado para {company_original_name} basado en los datos proporcionados.\",\n",
    "                management_report=company_docs.get('gestion', 'No disponible'),\n",
    "                sector=simulated_sector,\n",
    "                sector_report=company_docs.get('sectorial', 'No disponible'),\n",
    "                financial_report=company_docs.get('financiero', 'No disponible'),\n",
    "                response_va=response_va_simulated,\n",
    "                response_pp=response_pp_simulated,\n",
    "                df_desem_pag_cast_md=df_desem_pag_cast_md_str,\n",
    "                df_perfilador_md=df_perfilador_md_str,\n",
    "                products_list=simulated_products_list\n",
    "            )\n",
    "        except KeyError as e:\n",
    "            print(f\"ERROR: Placeholder '{e}' no encontrado en el prompt '{report_prompt_key}'. Revisa tu prompts.yml.\")\n",
    "            metrics[\"status\"] = \"failed\"\n",
    "            return metrics\n",
    "\n",
    "        full_messages = [\n",
    "            {\"role\": \"system\", \"content\": formatted_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_query if user_query else f\"Genera el reporte unificado para {company_original_name}.\"}\n",
    "        ]\n",
    "\n",
    "        # --- [TIMER] Generación prompt + invocación LLM (reporte) ---\n",
    "        llm_invocation_start_time = time.perf_counter()\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-4\", # Asegúrate de tener acceso a este modelo\n",
    "                temperature=0.0,\n",
    "                messages=full_messages\n",
    "            )\n",
    "            metrics[\"llm_api_latency\"] = time.perf_counter() - llm_invocation_start_time\n",
    "            \n",
    "            response_content = completion.choices[0].message.content\n",
    "            metrics[\"llm_input_tokens\"] = completion.usage.prompt_tokens\n",
    "            metrics[\"llm_output_tokens\"] = completion.usage.completion_tokens\n",
    "            \n",
    "            # Usar la misma métrica de latencia de API para el timer_metrics\n",
    "            metrics[\"timer_metrics\"][\"Generación prompt + invocación LLM (reporte)\"] = metrics[\"llm_api_latency\"] \n",
    "            \n",
    "            print(f\"Respuesta del LLM generada (primeros 200 chars): {response_content[:200]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR en invocación LLM: {e}\")\n",
    "            metrics[\"status\"] = \"failed\"\n",
    "            metrics[\"error\"] = str(e)\n",
    "            # Registrar el tiempo del intento incluso si falla\n",
    "            metrics[\"timer_metrics\"][\"Generación prompt + invocación LLM (reporte)\"] = time.perf_counter() - llm_invocation_start_time \n",
    "            response_content = \"ERROR\"\n",
    "    \n",
    "    # Captura el tiempo total del contexto principal al salir del 'with timer'\n",
    "    metrics[\"total_execution_time\"] = total_timer_result.elapsed_time\n",
    "\n",
    "    print(f\"\\n--- Métricas Finales para {company_original_name} ({report_prompt_key}) ---\")\n",
    "    print(f\"Tiempo Total de Ejecución: {metrics['total_execution_time']:.3f}s\")\n",
    "    print(f\"Latencia de Invocación LLM (aislada): {metrics['llm_api_latency']:.3f}s\")\n",
    "    print(f\"Tokens de Entrada LLM: {metrics['llm_input_tokens']}\")\n",
    "    print(f\"Tokens de Salida LLM: {metrics['llm_output_tokens']}\")\n",
    "    print(f\"Volumen de Transacciones procesadas: {metrics['data_processed_tx_rows']} filas\")\n",
    "    print(f\"Volumen de Financieros procesados: {metrics['data_processed_fin_rows']} filas\")\n",
    "    print(f\"Estado del flujo: {metrics['status']}\")\n",
    "    print(\"Tiempos por subproceso:\")\n",
    "    for k, v in metrics[\"timer_metrics\"].items():\n",
    "        if v is not None: # Asegurar que el valor no sea None antes de formatear\n",
    "            print(f\"  - {k}: {v:.3f}s\")\n",
    "        else:\n",
    "            print(f\"  - {k}: N/A (tiempo no capturado)\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6611185",
   "metadata": {},
   "source": [
    "## Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0f036d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Realizando una prueba de ejemplo para la empresa: Muñoz LLC S.A.S.\n",
      "\n",
      "--- Ejecutando flujo para Muñoz LLC S.A.S. (unified_report_1) ---\n",
      "[TIMER] Normalización y decisión de flujo: 0.006s\n",
      "[TIMER] Inicialización cliente e historial: 0.011s\n",
      "[TIMER] Configuración y modelos: 0.054s\n",
      "[TIMER] Carga documentos para empresa_1_Munoz_LLC_SAS: 0.001s\n",
      "[TIMER] Creación de PineconeManagers (carga de documentos): 0.002s\n",
      "[TIMER] Filtrado de dataframes por empresa (simulando query a BD): 0.002s\n",
      "[TIMER] Búsqueda similitud reporte unificado: 0.023s\n",
      "DEBUG: Tipo de t_rag_search_result después del bloque timer: <class 'utils.TimerResult'>\n",
      "DEBUG: Valor de t_rag_search_result.elapsed_time: 0.022735800000191375\n",
      "Respuesta del LLM generada (primeros 200 chars): 1. Descripción general de la empresa:\n",
      "\n",
      "Muñoz LLC S.A.S. es una empresa que ha consolidado su presencia en el mercado delectus, experimentando un crecimiento del 14% en sus operaciones en el último año...\n",
      "[TIMER] Tiempo total conversación: 19.198s\n",
      "\n",
      "--- Métricas Finales para Muñoz LLC S.A.S. (unified_report_1) ---\n",
      "Tiempo Total de Ejecución: 19.198s\n",
      "Latencia de Invocación LLM (aislada): 19.095s\n",
      "Tokens de Entrada LLM: 1895\n",
      "Tokens de Salida LLM: 608\n",
      "Volumen de Transacciones procesadas: 84 filas\n",
      "Volumen de Financieros procesados: 48 filas\n",
      "Estado del flujo: success\n",
      "Tiempos por subproceso:\n",
      "  - Normalización y decisión de flujo: N/A (tiempo no capturado)\n",
      "  - Inicialización cliente e historial: N/A (tiempo no capturado)\n",
      "  - Configuración y modelos: N/A (tiempo no capturado)\n",
      "  - Creación de PineconeManagers (carga de documentos): N/A (tiempo no capturado)\n",
      "  - Filtrado de dataframes por empresa (simulando query a BD): N/A (tiempo no capturado)\n",
      "  - Búsqueda similitud reporte unificado: 0.023s\n",
      "  - Generación prompt + invocación LLM (reporte): 19.095s\n",
      "\n",
      "--- Resultados Detallados de la Prueba de Ejemplo ---\n",
      "{\n",
      "  \"status\": \"success\",\n",
      "  \"total_execution_time\": 19.19809559999976,\n",
      "  \"llm_input_tokens\": 1895,\n",
      "  \"llm_output_tokens\": 608,\n",
      "  \"data_processed_tx_rows\": 84,\n",
      "  \"data_processed_fin_rows\": 48,\n",
      "  \"llm_api_latency\": 19.09533029999966,\n",
      "  \"timer_metrics\": {\n",
      "    \"Normalizaci\\u00f3n y decisi\\u00f3n de flujo\": null,\n",
      "    \"Inicializaci\\u00f3n cliente e historial\": null,\n",
      "    \"Configuraci\\u00f3n y modelos\": null,\n",
      "    \"Creaci\\u00f3n de PineconeManagers (carga de documentos)\": null,\n",
      "    \"Filtrado de dataframes por empresa (simulando query a BD)\": null,\n",
      "    \"B\\u00fasqueda similitud reporte unificado\": 0.022735800000191375,\n",
      "    \"Generaci\\u00f3n prompt + invocaci\\u00f3n LLM (reporte)\": 19.09533029999966\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Ejecutar Pruebas (Ejemplo) ---\n",
    "# Primero, asegúrate de haber ejecutado data_generator.py (o _light.py)\n",
    "# para que los archivos CSV, TXT y company_mapping.json existan.\n",
    "\n",
    "if not company_mapping:\n",
    "    print(\"No se pudo cargar el mapeo de empresas. Asegúrate de ejecutar el generador de datos primero.\")\n",
    "else:\n",
    "    test_company_data = company_mapping[0] # Tomamos la primera empresa del mapeo para la prueba de ejemplo\n",
    "    test_company_original_name = test_company_data[\"original_name\"]\n",
    "    test_company_sanitized_folder_name = test_company_data[\"sanitized_folder_name\"]\n",
    "\n",
    "    print(f\"\\nRealizando una prueba de ejemplo para la empresa: {test_company_original_name}\")\n",
    "    \n",
    "    if 'unified_report_1' in unified_report_prompts:\n",
    "        results = run_unified_report_flow(\n",
    "            company_original_name=test_company_original_name,\n",
    "            company_sanitized_folder_name=test_company_sanitized_folder_name,\n",
    "            report_prompt_key='unified_report_1',\n",
    "            user_query=\"Genera el resumen general de la empresa con los datos proporcionados.\"\n",
    "        )\n",
    "        print(\"\\n--- Resultados Detallados de la Prueba de Ejemplo ---\")\n",
    "        print(json.dumps(results, indent=2))\n",
    "    else:\n",
    "        print(\"El prompt 'unified_report_1' no está disponible en prompts.yml. Por favor, revisa tus prompts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5546862c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
