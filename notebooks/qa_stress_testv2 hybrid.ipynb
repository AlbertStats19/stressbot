{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e64227d",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e16b1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa_stress_test.ipynb\n",
    "\n",
    "# --- 0. Configuración Inicial y Carga de Librerías ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "from openai import OpenAI\n",
    "# Importación de utils asumiendo que está en la misma carpeta 'notebooks/'\n",
    "# Asegúrate de que utils.py contenga la clase TimerResult y el @contextmanager def timer(name): yield result\n",
    "from utils import timer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efd949c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para asegurar que se muestren todas las columnas de Pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c00ea0e",
   "metadata": {},
   "source": [
    "## path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36e89cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>> RUTA BASE PERSONALIZADA DEL PROYECTO (INTEGRACIÓN DE TU pk_) <<<<<\n",
    "# Esta ruta es esencial para que el notebook encuentre los archivos\n",
    "# generados por data_generator.py (data/, company_docs/, etc.)\n",
    "pk_ = \"C:/Users/Alber/OneDrive/Documentos/MADUREZ MLOPS/gerente-relacional-qa-test/\"\n",
    "# Puedes ajustar esta variable si la ubicación de tu proyecto cambia.\n",
    "# >>>>> FIN DE RUTA BASE PERSONALIZADA <<<<<"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e4a8fa",
   "metadata": {},
   "source": [
    "## open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99b1f9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando credenciales de OpenAI...\n",
      "Credenciales cargadas. Cliente OpenAI inicializado.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Cargar Credenciales ---\n",
    "print(\"Cargando credenciales de OpenAI...\")\n",
    "try:\n",
    "    # Usar pk_ para la ruta de credentials.json\n",
    "    with open(os.path.join('credentials.json')) as f:\n",
    "        config_env = json.load(f)\n",
    "    api_key = config_env[\"openai_key\"]\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    print(\"Credenciales cargadas. Cliente OpenAI inicializado.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: 'credentials.json' no encontrado en la ruta: {os.path.join(pk_, 'credentials.json')}. Asegúrate de crearlo en la raíz de tu proyecto ('{pk_}').\")\n",
    "    api_key = None\n",
    "    client = None\n",
    "except KeyError:\n",
    "    print(\"ERROR: 'openai_key' no encontrada en 'credentials.json'.\")\n",
    "    api_key = None\n",
    "    client = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6ec669",
   "metadata": {},
   "source": [
    "## YAML Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c97cfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cargando prompts desde prompts.yml...\n",
      "Prompts de reporte unificado cargados: ['unified_report_1', 'unified_report_2', 'unified_report_3', 'unified_report_4', 'unified_report_5']\n",
      "[TIMER] Carga de prompts y queries: 0.046s\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Cargar Prompts del Reporte Unificado ---\n",
    "print(\"\\nCargando prompts desde prompts.yml...\")\n",
    "# Usar pk_ para la ruta de prompts.yml\n",
    "prompts_path = os.path.join('prompts.yml')\n",
    "unified_report_prompts = {}\n",
    "with timer(\"Carga de prompts y queries\") as t_prompts: # Timer para esta etapa\n",
    "    try:\n",
    "        with open(prompts_path, 'r', encoding='utf-8') as file:\n",
    "            all_prompts = yaml.safe_load(file)\n",
    "        unified_report_prompts = {k: v for k, v in all_prompts.items() if k.startswith('unified_report_')}\n",
    "        print(f\"Prompts de reporte unificado cargados: {list(unified_report_prompts.keys())}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: '{prompts_path}' no encontrado.\")\n",
    "    except yaml.YAMLError as e:\n",
    "        print(f\"ERROR al parsear YAML: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdff580",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "354bb08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cargando datas simuladas...\n",
      "Data de transacciones cargada (LIGHT). Registros: 2000\n",
      "Data financiera cargada (LIGHT). Registros: 1000\n",
      "Mapeo de 25 empresas cargado.\n",
      "[TIMER] Carga de dataframes e historial: 0.026s\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Cargar Datas Simuladas (10M Transacciones y 300K Financieros) y Mapeo de Empresas ---\n",
    "print(\"\\nCargando datas simuladas...\")\n",
    "transactions_df = pd.DataFrame()\n",
    "financial_df = pd.DataFrame()\n",
    "company_mapping = [] # Lista de diccionarios {original_name, sanitized_folder_name}\n",
    "\n",
    "# Decide qué versión de datos cargar (LIGHT o FULL)\n",
    "USE_LIGHT_DATA = True # Cambia a False para usar los datos grandes (10M/300K)\n",
    "\n",
    "transactions_file = 'simulated_transactions.csv'\n",
    "financial_file = 'simulated_financial_metrics.csv'\n",
    "\n",
    "with timer(\"Carga de dataframes e historial\") as t_data_load: # Timer para esta etapa\n",
    "    try:\n",
    "        # Usar pk_ para la ruta de los archivos de datos\n",
    "        transactions_df = pd.read_csv(os.path.join(pk_, 'data', transactions_file))\n",
    "        print(f\"Data de transacciones cargada ({'LIGHT' if USE_LIGHT_DATA else 'FULL'}). Registros: {len(transactions_df)}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: '{transactions_file}' no encontrado en la ruta: '{os.path.join(pk_, 'data')}/'. Ejecuta data_generator.py (o _light.py).\")\n",
    "\n",
    "    try:\n",
    "        # Usar pk_ para la ruta de los archivos de datos\n",
    "        financial_df = pd.read_csv(os.path.join(pk_, 'data', financial_file))\n",
    "        print(f\"Data financiera cargada ({'LIGHT' if USE_LIGHT_DATA else 'FULL'}). Registros: {len(financial_df)}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: '{financial_file}' no encontrado en la ruta: '{os.path.join(pk_, 'data')}/'. Ejecuta data_generator.py (o _light.py).\")\n",
    "\n",
    "    # Cargar el mapeo de empresas\n",
    "    try:\n",
    "        # Usar pk_ para la ruta del mapeo de empresas\n",
    "        with open(os.path.join(pk_, 'data', 'company_mapping.json'), 'r', encoding='utf-8') as f:\n",
    "            company_mapping = json.load(f)\n",
    "        print(f\"Mapeo de {len(company_mapping)} empresas cargado.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: 'company_mapping.json' no encontrado en la ruta: '{os.path.join(pk_, 'data')}/'. Ejecuta data_generator.py (o _light.py).\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"ERROR: Fallo al leer 'company_mapping.json'. Asegúrate de que es un JSON válido.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc5b0b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>date</th>\n",
       "      <th>amount</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Posada-Peña S.A.S.</td>\n",
       "      <td>2024-09-10</td>\n",
       "      <td>586644.59</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>Libero porro quam modi incidunt.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id        company_name        date     amount   type                       description\n",
       "0               0  Posada-Peña S.A.S.  2024-09-10  586644.59  DEBIT  Libero porro quam modi incidunt."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e006b286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>financial_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>year</th>\n",
       "      <th>revenue</th>\n",
       "      <th>profit</th>\n",
       "      <th>liquidity_ratio</th>\n",
       "      <th>debt_equity_ratio</th>\n",
       "      <th>cash_flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Gómez-Cardozo S.A.S.</td>\n",
       "      <td>2021</td>\n",
       "      <td>14103440.43</td>\n",
       "      <td>19772809.19</td>\n",
       "      <td>0.69</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9111115.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   financial_id          company_name  year      revenue       profit  liquidity_ratio  debt_equity_ratio   cash_flow\n",
       "0             0  Gómez-Cardozo S.A.S.  2021  14103440.43  19772809.19             0.69                2.1  9111115.75"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec3d61a",
   "metadata": {},
   "source": [
    "## FLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84c11e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Función para Cargar Contenido de PDFs Simulados por Empresa (Tu versión adaptada) ---\n",
    "def load_company_documents(sanitized_folder_name):\n",
    "    \"\"\"Carga el contenido textual simulado de los PDFs para una empresa usando su nombre de carpeta sanitizado.\"\"\"\n",
    "    doc_contents = {}\n",
    "    # Usar pk_ para la ruta base de los documentos de las empresas\n",
    "    base_path = os.path.join(pk_, 'company_docs', sanitized_folder_name)\n",
    "    if not os.path.exists(base_path):\n",
    "        print(f\"Advertencia: Carpeta de documentos no encontrada para '{sanitized_folder_name}' en '{base_path}'\")\n",
    "        return doc_contents\n",
    "\n",
    "    # Este timer imprime su tiempo, pero su métrica se capturará indirectamente\n",
    "    # en \"Creación de PineconeManagers (carga de documentos)\" de run_unified_report_flow.\n",
    "    with timer(f\"Carga documentos para {sanitized_folder_name}\") as t_doc_load:\n",
    "        for doc_type in ['gestion', 'sectorial', 'financiero']:\n",
    "            file_path = os.path.join(base_path, f'{doc_type}.txt')\n",
    "            if os.path.exists(file_path):\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    doc_contents[doc_type] = f.read()\n",
    "            else:\n",
    "                doc_contents[doc_type] = \"\" # Vacío si no se encuentra el archivo\n",
    "    return doc_contents\n",
    "\n",
    "# --- 5. Lógica Principal de Generación de Reporte (Emulación del main.py) ---\n",
    "\n",
    "def run_unified_report_flow(company_original_name, company_sanitized_folder_name, report_prompt_key, user_query=\"\"):\n",
    "    \"\"\"\n",
    "    Ejecuta un flujo simulado de generación de reporte unificado para una empresa.\n",
    "    Mide tiempos y recolecta métricas.\n",
    "    \"\"\"\n",
    "    # Asegúrate de que client, unified_report_prompts, company_mapping, transactions_df, financial_df\n",
    "    # estén definidos globalmente o pasados como argumentos.\n",
    "    # Si no, esta comprobación fallará.\n",
    "    if 'client' not in globals() or client is None or \\\n",
    "       'unified_report_prompts' not in globals() or not unified_report_prompts or \\\n",
    "       'company_mapping' not in globals() or not company_mapping or \\\n",
    "       'transactions_df' not in globals() or transactions_df.empty or \\\n",
    "       'financial_df' not in globals() or financial_df.empty:\n",
    "        print(\"ERROR: Variables globales (client, prompts, mapping, dataframes) no inicializadas. Abortando.\")\n",
    "        return {\"status\": \"failed\", \"error\": \"Setup incomplete\"}\n",
    "\n",
    "\n",
    "    print(f\"\\n--- Ejecutando flujo para {company_original_name} ({report_prompt_key}) ---\")\n",
    "    metrics = {\n",
    "        \"status\": \"success\",\n",
    "        \"total_execution_time\": 0.0,\n",
    "        \"llm_input_tokens\": 0,\n",
    "        \"llm_output_tokens\": 0,\n",
    "        \"data_processed_tx_rows\": 0,\n",
    "        \"data_processed_fin_rows\": 0,\n",
    "        \"llm_api_latency\": 0.0, # Latencia de la llamada al LLM aislada\n",
    "        \"timer_metrics\": {} # Para guardar los tiempos de cada [TIMER]\n",
    "    }\n",
    "    \n",
    "    # Timer principal para el flujo completo\n",
    "    with timer(\"Tiempo total conversación\") as total_timer_result: \n",
    "        # --- [TIMER] Normalización y decisión de flujo: (SIMULADO)\n",
    "        with timer(\"Normalización y decisión de flujo\") as t_norm_result:\n",
    "            time.sleep(0.001) # Pequeña simulación de procesamiento\n",
    "        # >>>>> AÑADE ESTAS LÍNEAS PARA DEPURACIÓN <<<<<\n",
    "        print(f\"DEBUG_NORM: t_norm_result object: {t_norm_result}\")\n",
    "        if t_norm_result is not None:\n",
    "            print(f\"DEBUG_NORM: t_norm_result.elapsed_time: {t_norm_result.elapsed_time}\")\n",
    "        else:\n",
    "            print(\"DEBUG_NORM: t_norm_result es None.\")\n",
    "        # >>>>> FIN DE LÍNEAS DE DEPURACIÓN <<<<<\n",
    "        metrics[\"timer_metrics\"][\"Normalización y decisión de flujo\"] = t_norm_result.elapsed_time\n",
    "        \n",
    "        # --- [TIMER] Inicialización cliente e historial: (SIMULADO)\n",
    "        with timer(\"Inicialización cliente e historial\") as t_init_result:\n",
    "            time.sleep(0.01) # Pequeña simulación\n",
    "        # >>>>> AÑADE ESTAS LÍNEAS PARA DEPURACIÓN <<<<<\n",
    "        print(f\"DEBUG_INIT: t_init_result object: {t_init_result}\")\n",
    "        if t_init_result is not None:\n",
    "            print(f\"DEBUG_INIT: t_init_result.elapsed_time: {t_init_result.elapsed_time}\")\n",
    "        else:\n",
    "            print(\"DEBUG_INIT: t_init_result es None.\")\n",
    "        # >>>>> FIN DE LÍNEAS DE DEPURACIÓN <<<<<\n",
    "        metrics[\"timer_metrics\"][\"Inicialización cliente e historial\"] = t_init_result.elapsed_time\n",
    "\n",
    "        # --- [TIMER] Configuración y modelos: (SIMULADO)\n",
    "        with timer(\"Configuración y modelos\") as t_config_result:\n",
    "            time.sleep(0.05) # Simulación de tiempo para configuración\n",
    "        # >>>>> AÑADE ESTAS LÍNEAS PARA DEPURACIÓN <<<<<\n",
    "        print(f\"DEBUG_CONFIG: t_config_result object: {t_config_result}\")\n",
    "        if t_config_result is not None:\n",
    "            print(f\"DEBUG_CONFIG: t_config_result.elapsed_time: {t_config_result.elapsed_time}\")\n",
    "        else:\n",
    "            print(\"DEBUG_CONFIG: t_config_result es None.\")\n",
    "        # >>>>> FIN DE LÍNEAS DE DEPURACIÓN <<<<<\n",
    "        metrics[\"timer_metrics\"][\"Configuración y modelos\"] = t_config_result.elapsed_time\n",
    "        \n",
    "        # --- [TIMER] Creación de PineconeManagers (incluye carga de docs simulada):\n",
    "        with timer(\"Creación de PineconeManagers (carga de documentos)\") as t_pinecone_init_result:\n",
    "            company_docs = load_company_documents(company_sanitized_folder_name)\n",
    "        # >>>>> AÑADE ESTAS LÍNEAS PARA DEPURACIÓN <<<<<\n",
    "        print(f\"DEBUG_PINECONE: t_pinecone_init_result object: {t_pinecone_init_result}\")\n",
    "        if t_pinecone_init_result is not None:\n",
    "            print(f\"DEBUG_PINECONE: t_pinecone_init_result.elapsed_time: {t_pinecone_init_result.elapsed_time}\")\n",
    "        else:\n",
    "            print(\"DEBUG_PINECONE: t_pinecone_init_result es None.\")\n",
    "        # >>>>> FIN DE LÍNEAS DE DEPURACIÓN <<<<<\n",
    "        metrics[\"timer_metrics\"][\"Creación de PineconeManagers (carga de documentos)\"] = t_pinecone_init_result.elapsed_time\n",
    "        \n",
    "        # --- Preparar el Prompt Final para el LLM ---\n",
    "        current_report_prompt_template = unified_report_prompts.get(report_prompt_key)\n",
    "        if not current_report_prompt_template:\n",
    "            print(f\"ERROR: Prompt '{report_prompt_key}' no encontrado.\")\n",
    "            metrics[\"status\"] = \"failed\"\n",
    "            return metrics\n",
    "        \n",
    "        # --- [TIMER] Filtrado de dataframes por empresa (simulando query a BD) ---\n",
    "        with timer(\"Filtrado de dataframes por empresa (simulando query a BD)\") as t_filter_df_result:\n",
    "            company_transactions_df = transactions_df[transactions_df['company_name'] == company_original_name].copy()\n",
    "            company_financial_df = financial_df[financial_df['company_name'] == company_original_name].copy()\n",
    "            metrics[\"data_processed_tx_rows\"] = len(company_transactions_df)\n",
    "            metrics[\"data_processed_fin_rows\"] = len(company_financial_df)\n",
    "        # >>>>> AÑADE ESTAS LÍNEAS PARA DEPURACIÓN <<<<<\n",
    "        print(f\"DEBUG_FILTER: t_filter_df_result object: {t_filter_df_result}\")\n",
    "        if t_filter_df_result is not None:\n",
    "            print(f\"DEBUG_FILTER: t_filter_df_result.elapsed_time: {t_filter_df_result.elapsed_time}\")\n",
    "        else:\n",
    "            print(\"DEBUG_FILTER: t_filter_df_result es None.\")\n",
    "        # >>>>> FIN DE LÍNEAS DE DEPURACIÓN <<<<<\n",
    "        metrics[\"timer_metrics\"][\"Filtrado de dataframes por empresa (simulando query a BD)\"] = t_filter_df_result.elapsed_time\n",
    "\n",
    "        # --- [TIMER] Búsqueda similitud reporte unificado (simulando Pinecone/RAG):\n",
    "        with timer(\"Búsqueda similitud reporte unificado\") as t_rag_search_result:\n",
    "            context_from_docs = company_docs.get('gestion', '') + \"\\n\\n\" + \\\n",
    "                                company_docs.get('sectorial', '') + \"\\n\\n\" + \\\n",
    "                                company_docs.get('financiero', '')\n",
    "            \n",
    "            time.sleep(0.01 + len(context_from_docs) / 1000000.0)\n",
    "            \n",
    "        # Esta ya la teníamos, la dejo para consistencia\n",
    "        print(f\"DEBUG_RAG: Tipo de t_rag_search_result después del bloque timer: {type(t_rag_search_result)}\")\n",
    "        if t_rag_search_result is not None:\n",
    "            print(f\"DEBUG_RAG: Valor de t_rag_search_result.elapsed_time: {t_rag_search_result.elapsed_time}\")\n",
    "        else:\n",
    "            print(\"DEBUG_RAG: t_rag_search_result es None.\")\n",
    "        metrics[\"timer_metrics\"][\"Búsqueda similitud reporte unificado\"] = t_rag_search_result.elapsed_time\n",
    "\n",
    "        # --- Rellenar los placeholders del prompt ---\n",
    "        simulated_products_list = \"Préstamos Comerciales, Créditos de Liquidez, Cuentas de Ahorro, CDT.\"\n",
    "        simulated_sector = \"Tecnología y Servicios Financieros\" \n",
    "\n",
    "        df_desem_pag_cast_md_str = company_transactions_df.head(5).to_markdown(index=False)\n",
    "        df_perfilador_md_str = company_financial_df.head(5).to_markdown(index=False)\n",
    "\n",
    "        response_va_simulated = \"Según Valora Analitik, la empresa ha invertido en IA para optimizar procesos bancarios.\"\n",
    "        response_pp_simulated = \"En Primera Página se destacó la expansión regional de la empresa en el último año.\"\n",
    "\n",
    "        try:\n",
    "            formatted_prompt = current_report_prompt_template.format(\n",
    "                company_name=company_original_name,\n",
    "                user_request=user_query if user_query else f\"Genera un reporte unificado para {company_original_name} basado en los datos proporcionados.\",\n",
    "                management_report=company_docs.get('gestion', 'No disponible'),\n",
    "                sector=simulated_sector,\n",
    "                sector_report=company_docs.get('sectorial', 'No disponible'),\n",
    "                financial_report=company_docs.get('financiero', 'No disponible'),\n",
    "                response_va=response_va_simulated,\n",
    "                response_pp=response_pp_simulated,\n",
    "                df_desem_pag_cast_md=df_desem_pag_cast_md_str,\n",
    "                df_perfilador_md=df_perfilador_md_str,\n",
    "                products_list=simulated_products_list\n",
    "            )\n",
    "        except KeyError as e:\n",
    "            print(f\"ERROR: Placeholder '{e}' no encontrado en el prompt '{report_prompt_key}'. Revisa tu prompts.yml.\")\n",
    "            metrics[\"status\"] = \"failed\"\n",
    "            return metrics\n",
    "\n",
    "        full_messages = [\n",
    "            {\"role\": \"system\", \"content\": formatted_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_query if user_query else f\"Genera el reporte unificado para {company_original_name}.\"}\n",
    "        ]\n",
    "\n",
    "        # --- [TIMER] Generación prompt + invocación LLM (reporte) ---\n",
    "        llm_invocation_start_time = time.perf_counter()\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-4\", # Asegúrate de tener acceso a este modelo\n",
    "                temperature=0.0,\n",
    "                messages=full_messages\n",
    "            )\n",
    "            metrics[\"llm_api_latency\"] = time.perf_counter() - llm_invocation_start_time\n",
    "            \n",
    "            response_content = completion.choices[0].message.content\n",
    "            metrics[\"llm_input_tokens\"] = completion.usage.prompt_tokens\n",
    "            metrics[\"llm_output_tokens\"] = completion.usage.completion_tokens\n",
    "            \n",
    "            # Usar la misma métrica de latencia de API para el timer_metrics\n",
    "            metrics[\"timer_metrics\"][\"Generación prompt + invocación LLM (reporte)\"] = metrics[\"llm_api_latency\"] \n",
    "            \n",
    "            print(f\"Respuesta del LLM generada (primeros 200 chars): {response_content[:200]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR en invocación LLM: {e}\")\n",
    "            metrics[\"status\"] = \"failed\"\n",
    "            metrics[\"error\"] = str(e)\n",
    "            # Registrar el tiempo del intento incluso si falla\n",
    "            metrics[\"timer_metrics\"][\"Generación prompt + invocación LLM (reporte)\"] = time.perf_counter() - llm_invocation_start_time \n",
    "            response_content = \"ERROR\"\n",
    "    \n",
    "    # Captura el tiempo total del contexto principal al salir del 'with timer'\n",
    "    metrics[\"total_execution_time\"] = total_timer_result.elapsed_time\n",
    "\n",
    "    print(f\"\\n--- Métricas Finales para {company_original_name} ({report_prompt_key}) ---\")\n",
    "    print(f\"Tiempo Total de Ejecución: {metrics['total_execution_time']:.3f}s\")\n",
    "    print(f\"Latencia de Invocación LLM (aislada): {metrics['llm_api_latency']:.3f}s\")\n",
    "    print(f\"Tokens de Entrada LLM: {metrics['llm_input_tokens']}\")\n",
    "    print(f\"Tokens de Salida LLM: {metrics['llm_output_tokens']}\")\n",
    "    print(f\"Volumen de Transacciones procesadas: {metrics['data_processed_tx_rows']} filas\")\n",
    "    print(f\"Volumen de Financieros procesados: {metrics['data_processed_fin_rows']} filas\")\n",
    "    print(f\"Estado del flujo: {metrics['status']}\")\n",
    "    print(\"Tiempos por subproceso:\")\n",
    "    for k, v in metrics[\"timer_metrics\"].items():\n",
    "        if v is not None: # Asegurar que el valor no sea None antes de formatear\n",
    "            print(f\"  - {k}: {v:.3f}s\")\n",
    "        else:\n",
    "            print(f\"  - {k}: N/A (tiempo no capturado)\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6611185",
   "metadata": {},
   "source": [
    "## Latencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88a9a935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'original_name': 'Muñoz LLC S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_1_Munoz_LLC_SAS'},\n",
       " {'original_name': 'Posada-Peña S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_2_Posada-Pena_SAS'},\n",
       " {'original_name': 'González Inc S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_3_Gonzalez_Inc_SAS'},\n",
       " {'original_name': 'Gil-Salazar S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_4_Gil-Salazar_SAS'},\n",
       " {'original_name': 'Galvis, Ramírez and Angarita S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_5_Galvis_Ramirez_and_Angarita_SAS'},\n",
       " {'original_name': 'Gómez, Sanabria and Pulido S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_6_Gomez_Sanabria_and_Pulido_SAS'},\n",
       " {'original_name': 'Buitrago, García and García S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_7_Buitrago_Garcia_and_Garcia_SAS'},\n",
       " {'original_name': 'Reyes-Zambrano S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_8_Reyes-Zambrano_SAS'},\n",
       " {'original_name': 'Pacheco, Velandia and Ávila S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_9_Pacheco_Velandia_and_Avila_SAS'},\n",
       " {'original_name': 'Durán-Bernal S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_10_Duran-Bernal_SAS'},\n",
       " {'original_name': 'Mosquera-Medina S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_11_Mosquera-Medina_SAS'},\n",
       " {'original_name': 'Ramírez LLC S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_12_Ramirez_LLC_SAS'},\n",
       " {'original_name': 'Portilla-Palacios S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_13_Portilla-Palacios_SAS'},\n",
       " {'original_name': 'Oviedo-Domínguez S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_14_Oviedo-Dominguez_SAS'},\n",
       " {'original_name': 'Gómez-Cardozo S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_15_Gomez-Cardozo_SAS'},\n",
       " {'original_name': 'Reyes, Álvarez and Hernández S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_16_Reyes_Alvarez_and_Hernandez_SAS'},\n",
       " {'original_name': 'Flórez Ltd S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_17_Florez_Ltd_SAS'},\n",
       " {'original_name': 'Rodríguez-Martínez S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_18_Rodriguez-Martinez_SAS'},\n",
       " {'original_name': 'García, Castro and Rendón S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_19_Garcia_Castro_and_Rendon_SAS'},\n",
       " {'original_name': 'Vargas-Álvarez S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_20_Vargas-Alvarez_SAS'},\n",
       " {'original_name': 'Garcés-Buitrago S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_21_Garces-Buitrago_SAS'},\n",
       " {'original_name': 'Calderón and Sons S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_22_Calderon_and_Sons_SAS'},\n",
       " {'original_name': 'Jaimes-Quintero S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_23_Jaimes-Quintero_SAS'},\n",
       " {'original_name': 'Castro-Flórez S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_24_Castro-Florez_SAS'},\n",
       " {'original_name': 'Palacios, Becerra and Rodríguez S.A.S.',\n",
       "  'sanitized_folder_name': 'empresa_25_Palacios_Becerra_and_Rodriguez_SAS'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b32a447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unified_report_1': 'Eres un analista experto en la elaboración de informes gerenciales para el área comercial del Banco de Bogotá. Tu objetivo, juanto con otros analistas, es generar un informe estratégico comercial (detallado) que busca profundizar relaciones con el cliente {company_name}. Tienes asignado uno de los puntos del informe general.\\nPara lograr tu tarea dentro de la división (entre analistas) de objetivo, sigue esta estructura, asegurando calidad analítica y redacción clara. Importante evitar repetir datos entre secciones (especialmente cifras, conclusiones y diagnósticos):\\n\\n1. Descripción general de la empresa: a partir de toda la información suministrada realiza un resumen que incluya la actividad de la empresa {company_name}; sus principales productos y servicios (realiza una lista que contenga descripciones breves para cada elemento); quiénes son los clientes de la empresa {company_name}; información de los competidores directos de la empresa {company_name} en el mercado; la información sobre su cadena de suministros; estructura organizacional especificando nombres y cargos solo si existe la información; gestión de talento humano de la compañia (cantidad de empleados), Información de todos los proyectos de inversión o planes de inversiones de capital contemplados por la empresa {company_name}; describe todos los proyectos de huella de carbono y cuales son las estrategias tanto ambientales, como sociales o de otro tipo.\\n\\nAdiciona un parrafo que describa la situación actual de la compañía (máximo 200 palabras) que resuma el estado actual de la empresa {company_name}, enfocándote en su situación financiera, desempeño reciente y posibles señales de alerta o estabilidad. Una forma de apoyarte es utilizar la información del apartado \"Información de contexto de la empresa\".\\n\\n    ----------------------------------------------------------\\n    Información para lograr el objetivo:\\n\\n    * Nombre de la compañía sobre la que se consulta: {company_name}\\n\\n    * Información de contexto de la empresa consultada [fuente: Reporte de gestión {company_name}]: {management_report}\\n\\n    * Informe de la situacion actual del sector {sector} [fuente: Reporte Sectorial]: {sector_report}\\n\\n    * Información de contexto financiero de la empresa consultada [fuente: Reporte financiero {company_name}]: {financial_report}\\n\\n    * Informe marco normativo [fuente: publicaciones obtenidas de portales de noticias externos]:\\n        - Conocimiento obtenido desde fuente Valora Analitik:\\n            {response_va}\\n\\n        - Conocimiento obtenido desde fuente Primera Página [fuente: podcast Primera Página]: \\n            {response_pp}\\n\\n    * DataFrame \"df_desem_pag_cast_md\" [fuente: base de datos \"desemb_pagos_castigos\" interna del Banco de Bogotá]: {df_desem_pag_cast_md}\\n\\n    * DataFrame \"df_perfilador_md\" [fuente: base de datos \"perfilador\" interna del Banco de Bogotá]: {df_perfilador_md}\\n    ----------------------------------------------------------\\n\\nEl informe completo que creas no debe perder información, datos, valores o cifras (puesto que no es estrictamente un resumen), sino que debe centrarse en organizar la información de las bases de conocimiento en la estructura solicitada (en formato MarkDown).\\n\\nTu respuesta debe ser exclusivamente sobre el fragmento asignado, por lo que si se hace referencia a la parte 1, 2, 3, 4, etc., deberás responder siempre haciendo alusión a ese número de apartado.\\n',\n",
       " 'unified_report_2': 'Eres un analista experto en la elaboración de informes gerenciales para el área comercial del Banco de Bogotá. Tu objetivo, juanto con otros analistas, es generar un informe estratégico comercial (detallado) que busca profundizar relaciones con el cliente {company_name}. Tienes asignado uno de los puntos del informe general.\\nPara lograr tu tarea dentro de la división (entre analistas) de objetivo, sigue esta estructura, asegurando calidad analítica y redacción clara. Importante evitar repetir datos entre secciones (especialmente cifras, conclusiones y diagnósticos):\\n\\n2. Resumen financiero: teniendo en cuenta secciones como la de \"Información de contexto de la empresa\" y la de \"DataFrame df_perfilador\" (sin cerrarte exclusivamente en estas dos):\\n    2.1. Presenta las principales cifras y sus variaciones del Estado de resultados en formato de una tabla comparativa por año en el siguiente orden: Ingresos o ventas; gastos; utilidades, rentabilidad o excedente contable (renombrar como utilidad); situación de flujo de caja o flujo de efectivo neto de la empresa. Por otra parte, detalla las cifras con sus respectivas variaciones del estado de situación financiera en formato de una tabla comparativa por año en el siguiente orden: activos, pasivos, patrimonio e indicadores de liquidez que sean claves para un gerente comercial de un banco.\\n    2.2. Incluye comparativos anuales si se encuentran en tus fuentes de información.\\n\\n    ----------------------------------------------------------\\n    Información para lograr el objetivo:\\n\\n    * Nombre de la compañía sobre la que se consulta: {company_name}\\n\\n    * Información de contexto de la empresa consultada [fuente: Reporte de gestión {company_name}]: {management_report}\\n\\n    * Informe de la situacion actual del sector {sector} [fuente: Reporte Sectorial]: {sector_report}\\n\\n    * Información de contexto financiero de la empresa consultada [fuente: Reporte financiero {company_name}]: {financial_report}\\n\\n    * Informe marco normativo [fuente: publicaciones obtenidas de portales de noticias externos]:\\n        - Conocimiento obtenido desde fuente Valora Analitik:\\n            {response_va}\\n\\n        - Conocimiento obtenido desde fuente Primera Página [fuente: podcast Primera Página]: \\n            {response_pp}\\n\\n    * DataFrame \"df_desem_pag_cast_md\" [fuente: base de datos \"desemb_pagos_castigos\" interna del Banco de Bogotá]: {df_desem_pag_cast_md}\\n\\n    * DataFrame \"df_perfilador_md\" [fuente: base de datos \"perfilador\" interna del Banco de Bogotá]: {df_perfilador_md}\\n    ----------------------------------------------------------\\n\\nEl informe completo que creas no debe perder información, datos, valores o cifras (puesto que no es estrictamente un resumen), sino que debe centrarse en organizar la información de las bases de conocimiento en la estructura solicitada (en formato MarkDown).\\n\\nTu respuesta debe ser exclusivamente sobre el fragmento asignado, por lo que si se hace referencia a la parte 1, 2, 3, 4, etc., deberás responder siempre haciendo alusión a ese número de apartado.\\n',\n",
       " 'unified_report_3': 'Eres un analista experto en la elaboración de informes gerenciales para el área comercial del Banco de Bogotá. Tu objetivo, juanto con otros analistas, es generar un informe estratégico comercial (detallado) que busca profundizar relaciones con el cliente {company_name}. Tienes asignado uno de los puntos del informe general.\\nPara lograr tu tarea dentro de la división (entre analistas) de objetivo, sigue esta estructura, asegurando calidad analítica y redacción clara. Importante evitar repetir datos entre secciones (especialmente cifras, conclusiones y diagnósticos):\\n\\n3. Relación actual con el Banco de Bogotá: describe la información de productos, saldos de productos (valores sin decimales), indicadores de utilidad (margen de contribución) y nivel de endeudamiento de la empresa {company_name} con el Banco de Bogotá, utilizando los siguientes datos disponibles:\\n    3.1. Saldos de productos activos por periodo (podría ser útil la información dispuesta en el apartado \"DataFrame df_saldos_total\"), teniendo en cuenta el siguiente orden: Préstamos comerciales, Créditos de Liquidez, Ahorro Superdia Especial, CDT, cuentas de ahorro, corriente, etc.\\n    3.2. Información sobre desembolsos (podría ser útil la información dispuesta en el apartado \"DataFrame df_desemb_pagos_castigos\").\\n    3.3. Margen de contribución, detalla el valor del margen de contribución (podría ser útil la información dispuesta en el apartado \"DataFrame df_perfilador\").\\n    3.4. Niveles de endeudamiento total (podría ser útil la información dispuesta en el apartado \"DataFrame df_perfilador\"), detalla el endeudamiento que tiene la empresa {company_name} con el Banco de Bogotá y con otros bancos; agrega el porcentaje de participación de cada banco. Deja como primer registro de la tabla el endeudamiento con Banco de Bogotá y después los otros bancos ordenados según sus porcentajes de participación, es decir: siempre estará el Banco de Bogotá con su porcentaje en primera posición y las posiciones siguientes serán ocupadas con los bancos que tengan los mayores porcentajes de participación (no importa que estos porcentajes sean mayores al del Banco de Bogotá, puesto que éste tendrá la prioridad en todo los casos).\\n    3.5. Participación accionaria, describe únicamente la información de los accionistas de la empresa (podría ser útil la información dispuesta en el apartado \"DataFrame df_emis\").\\n    3.6. Calificación crediticia y perfil de riesgo (podría ser útil la información dispuesta en el apartado \"DataFrame df_perfilador\").\\n\\n    ----------------------------------------------------------\\n    Información para lograr el objetivo:\\n\\n    * Nombre de la compañía sobre la que se consulta: {company_name}\\n\\n    * Información de contexto de la empresa consultada [fuente: Reporte de gestión {company_name}]: {management_report}\\n\\n    * Informe de la situacion actual del sector {sector} [fuente: Reporte Sectorial]: {sector_report}\\n\\n    * Información de contexto financiero de la empresa consultada [fuente: Reporte financiero {company_name}]: {financial_report}\\n\\n    * Informe marco normativo [fuente: publicaciones obtenidas de portales de noticias externos]:\\n        - Conocimiento obtenido desde fuente Valora Analitik:\\n            {response_va}\\n\\n        - Conocimiento obtenido desde fuente Primera Página [fuente: podcast Primera Página]: \\n            {response_pp}\\n\\n    * DataFrame \"df_desem_pag_cast_md\" [fuente: base de datos \"desemb_pagos_castigos\" interna del Banco de Bogotá]: {df_desem_pag_cast_md}\\n\\n    * DataFrame \"df_perfilador_md\" [fuente: base de datos \"perfilador\" interna del Banco de Bogotá]: {df_perfilador_md}\\n    ----------------------------------------------------------\\n\\nEl informe completo que creas no debe perder información, datos, valores o cifras (puesto que no es estrictamente un resumen), sino que debe centrarse en organizar la información de las bases de conocimiento en la estructura solicitada (en formato MarkDown).\\n\\nTu respuesta debe ser exclusivamente sobre el fragmento asignado, por lo que si se hace referencia a la parte 1, 2, 3, 4, etc., deberás responder siempre haciendo alusión a ese número de apartado.\\n',\n",
       " 'unified_report_4': 'Eres un analista experto en la elaboración de informes gerenciales para el área comercial del Banco de Bogotá. Tu objetivo, juanto con otros analistas, es generar un informe estratégico comercial (detallado) que busca profundizar relaciones con el cliente {company_name}. Tienes asignado uno de los puntos del informe general.\\nPara lograr tu tarea dentro de la división (entre analistas) de objetivo, sigue esta estructura, asegurando calidad analítica y redacción clara. Importante evitar repetir datos entre secciones (especialmente cifras, conclusiones y diagnósticos):\\n\\n\\n4. Noticias relevantes: centrandote en la información brindada en los apartados \"Informe marco normativo (Valora Analitik)\" y \"Informe marco normativo (Primera Página)\" bríndame un informe que procuré enfocarse en los siguientes aspectos (o con un enfoque similar):\\n    4.1. Expansiones de mercado; nuevos puntos de venta o cierres de operaciones.\\n    4.2. Inversiones (nivel nacional o internacional si aplica).\\n    4.3. Cambios regulatorios (noticias de la bolsa de valores, nuevas normas, regulaciones internas o externas) que le aplican a la empresa.\\n\\nImportante: Incluye la fuente de información de la noticia (Valora Analitik y Primera Página) y la fecha de publicación en caso de contar con dicho dato; no inventes o coloques un valor de fecha si no está en la información brindada.\\n\\n\\n    ----------------------------------------------------------\\n    Información para lograr el objetivo:\\n\\n    * Nombre de la compañía sobre la que se consulta: {company_name}\\n\\n    * Información de contexto de la empresa consultada [fuente: Reporte de gestión {company_name}]: {management_report}\\n\\n    * Informe de la situacion actual del sector {sector} [fuente: Reporte Sectorial]: {sector_report}\\n\\n    * Información de contexto financiero de la empresa consultada [fuente: Reporte financiero {company_name}]: {financial_report}\\n\\n    * Informe marco normativo [fuente: publicaciones obtenidas de portales de noticias externos]:\\n        - Conocimiento obtenido desde fuente Valora Analitik:\\n            {response_va}\\n\\n        - Conocimiento obtenido desde fuente Primera Página [fuente: podcast Primera Página]: \\n            {response_pp}\\n\\n    * DataFrame \"df_desem_pag_cast_md\" [fuente: base de datos \"desemb_pagos_castigos\" interna del Banco de Bogotá]: {df_desem_pag_cast_md}\\n\\n    * DataFrame \"df_perfilador_md\" [fuente: base de datos \"perfilador\" interna del Banco de Bogotá]: {df_perfilador_md}\\n    ----------------------------------------------------------\\n\\nEl informe completo que creas no debe perder información, datos, valores o cifras (puesto que no es estrictamente un resumen), sino que debe centrarse en organizar la información de las bases de conocimiento en la estructura solicitada (en formato MarkDown).\\n\\nTu respuesta debe ser exclusivamente sobre el fragmento asignado, por lo que si se hace referencia a la parte 1, 2, 3, 4, etc., deberás responder siempre haciendo alusión a ese número de apartado.\\n',\n",
       " 'unified_report_5': 'Eres un analista experto en la elaboración de informes gerenciales para el área comercial del Banco de Bogotá. Tu objetivo, juanto con otros analistas, es generar un informe estratégico comercial (detallado) que busca profundizar relaciones con el cliente {company_name}. Tienes asignado uno de los puntos del informe general.\\nPara lograr tu tarea dentro de la división (entre analistas) de objetivo, sigue esta estructura, asegurando calidad analítica y redacción clara. Importante evitar repetir datos entre secciones (especialmente cifras, conclusiones y diagnósticos):\\n\\n5. Oportunidades identificadas: Actúa como un asesor comercial Senior del Banco de Bogotá, tu labor es analizar en profundidad toda la información recopilada anteriormente, incluyendo cifras de (Descripción general de la empresa, Resumen financiero, Relación actual con el Banco de Bogotá y Noticias relevantes), busca e identifica oportunidades reales de la empresa {company_name} que puedan ser solucionadas o apoyadas por los productos y servicios financieros del Banco de Bogotá. Debes tener en cuenta: la información financiera; ratios financieros; proyectos o inversiones anunciadas; retos organizacionales o normativos; alertas de riesgo; iniciativas ESG: ambiental, social y de gobernanza; necesidades de liquidez; inversiones a futuro; información de empleados; proyectos de impacto y huella de carbono y proyectos tecnologicos de la empresa {company_name}:\\n\\n    5.1. Generar las 3–6 mejores oportunidades comerciales para la empresa {company_name}. Importante que las oportunidades no sean genéricas y evita recomendaciones débiles. \\n    Además debes asociar cada oportunidad identificada al producto y/o servicio del Banco de Bogotá que tenga mayor afinidad según el siguiente listado de productos: \\n    {products_list}\\n\\n    Presenta una tabla donde se agrupen las oportunidades con la siguiente estructura:\\n    Oportunidad: título breve\\n    Insight clave: debes incluir: el Dato, la cifra o hecho concreto de la información analizada que motiva la oportunidad\\n    Producto/estructura recomendada: Mencione el producto o servicio del Banco de Bogotá con su descripción especifica.\\n    Justificación personalizada: Describe por qué este producto o servicio del Banco de Bogotá encaja con la oportunidad la empresa {company_name}, no olvides mencionar el beneficio del producto o servicio.\\n    Frase de consulta para el cliente: Con base a la oportunidad, elabora una pregunta con enfoque comercial para que el asesor consulte a la empresa {company_name} si han contemplado este tipo de productos o servicios financieros. \\n\\n    Finalmente ordena las oportunidades por impacto estimado (alto -> prioridad 1, medio -> prioridad 2, etc.).\\n\\n\\n    ----------------------------------------------------------\\n    Información para lograr el objetivo:\\n\\n    * Nombre de la compañía sobre la que se consulta: {company_name}\\n\\n    * Información de contexto de la empresa consultada [fuente: Reporte de gestión {company_name}]: {management_report}\\n\\n    * Informe de la situacion actual del sector {sector} [fuente: Reporte Sectorial]: {sector_report}\\n\\n    * Información de contexto financiero de la empresa consultada [fuente: Reporte financiero {company_name}]: {financial_report}\\n\\n    * Informe marco normativo [fuente: publicaciones obtenidas de portales de noticias externos]:\\n        - Conocimiento obtenido desde fuente Valora Analitik:\\n            {response_va}\\n\\n        - Conocimiento obtenido desde fuente Primera Página [fuente: podcast Primera Página]: \\n            {response_pp}\\n\\n    * DataFrame \"df_desem_pag_cast_md\" [fuente: base de datos \"desemb_pagos_castigos\" interna del Banco de Bogotá]: {df_desem_pag_cast_md}\\n\\n    * DataFrame \"df_perfilador_md\" [fuente: base de datos \"perfilador\" interna del Banco de Bogotá]: {df_perfilador_md}\\n    ----------------------------------------------------------\\n\\nEl informe completo que creas no debe perder información, datos, valores o cifras (puesto que no es estrictamente un resumen), sino que debe centrarse en organizar la información de las bases de conocimiento en la estructura solicitada (en formato MarkDown).\\n\\nTu respuesta debe ser exclusivamente sobre el fragmento asignado, por lo que si se hace referencia a la parte 1, 2, 3, 4, etc., deberás responder siempre haciendo alusión a ese número de apartado.\\n'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unified_report_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c0f036d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Realizando una prueba de ejemplo para la empresa: Muñoz LLC S.A.S.\n",
      "\n",
      "--- Ejecutando flujo para Muñoz LLC S.A.S. (unified_report_1) ---\n",
      "[TIMER] Normalización y decisión de flujo: 0.004s\n",
      "DEBUG_NORM: t_norm_result object: <utils.TimerResult object at 0x0000019E08CD15D0>\n",
      "DEBUG_NORM: t_norm_result.elapsed_time: 0.003963099996326491\n",
      "[TIMER] Inicialización cliente e historial: 0.010s\n",
      "DEBUG_INIT: t_init_result object: <utils.TimerResult object at 0x0000019E08CD1360>\n",
      "DEBUG_INIT: t_init_result.elapsed_time: 0.01006000000052154\n",
      "[TIMER] Configuración y modelos: 0.051s\n",
      "DEBUG_CONFIG: t_config_result object: <utils.TimerResult object at 0x0000019E08CD3550>\n",
      "DEBUG_CONFIG: t_config_result.elapsed_time: 0.051328399997146334\n",
      "[TIMER] Carga documentos para empresa_1_Munoz_LLC_SAS: 0.003s\n",
      "[TIMER] Creación de PineconeManagers (carga de documentos): 0.003s\n",
      "DEBUG_PINECONE: t_pinecone_init_result object: <utils.TimerResult object at 0x0000019E08CD0A90>\n",
      "DEBUG_PINECONE: t_pinecone_init_result.elapsed_time: 0.0031190999943646602\n",
      "[TIMER] Filtrado de dataframes por empresa (simulando query a BD): 0.004s\n",
      "DEBUG_FILTER: t_filter_df_result object: <utils.TimerResult object at 0x0000019E08CD1660>\n",
      "DEBUG_FILTER: t_filter_df_result.elapsed_time: 0.004095799995411653\n",
      "[TIMER] Búsqueda similitud reporte unificado: 0.017s\n",
      "DEBUG_RAG: Tipo de t_rag_search_result después del bloque timer: <class 'utils.TimerResult'>\n",
      "DEBUG_RAG: Valor de t_rag_search_result.elapsed_time: 0.016632899998512585\n",
      "Respuesta del LLM generada (primeros 200 chars): 1. Descripción general de la empresa:\n",
      "\n",
      "Muñoz LLC S.A.S. es una empresa que ha consolidado su presencia en el mercado delectus, experimentando un crecimiento del 14% en sus operaciones en el último año...\n",
      "[TIMER] Tiempo total conversación: 23.615s\n",
      "\n",
      "--- Métricas Finales para Muñoz LLC S.A.S. (unified_report_1) ---\n",
      "Tiempo Total de Ejecución: 23.615s\n",
      "Latencia de Invocación LLM (aislada): 23.502s\n",
      "Tokens de Entrada LLM: 1895\n",
      "Tokens de Salida LLM: 464\n",
      "Volumen de Transacciones procesadas: 84 filas\n",
      "Volumen de Financieros procesados: 48 filas\n",
      "Estado del flujo: success\n",
      "Tiempos por subproceso:\n",
      "  - Normalización y decisión de flujo: 0.004s\n",
      "  - Inicialización cliente e historial: 0.010s\n",
      "  - Configuración y modelos: 0.051s\n",
      "  - Creación de PineconeManagers (carga de documentos): 0.003s\n",
      "  - Filtrado de dataframes por empresa (simulando query a BD): 0.004s\n",
      "  - Búsqueda similitud reporte unificado: 0.017s\n",
      "  - Generación prompt + invocación LLM (reporte): 23.502s\n",
      "\n",
      "--- Resultados Detallados de la Prueba de Ejemplo ---\n",
      "{\n",
      "  \"status\": \"success\",\n",
      "  \"total_execution_time\": 23.615234199998667,\n",
      "  \"llm_input_tokens\": 1895,\n",
      "  \"llm_output_tokens\": 464,\n",
      "  \"data_processed_tx_rows\": 84,\n",
      "  \"data_processed_fin_rows\": 48,\n",
      "  \"llm_api_latency\": 23.50188160000107,\n",
      "  \"timer_metrics\": {\n",
      "    \"Normalizaci\\u00f3n y decisi\\u00f3n de flujo\": 0.003963099996326491,\n",
      "    \"Inicializaci\\u00f3n cliente e historial\": 0.01006000000052154,\n",
      "    \"Configuraci\\u00f3n y modelos\": 0.051328399997146334,\n",
      "    \"Creaci\\u00f3n de PineconeManagers (carga de documentos)\": 0.0031190999943646602,\n",
      "    \"Filtrado de dataframes por empresa (simulando query a BD)\": 0.004095799995411653,\n",
      "    \"B\\u00fasqueda similitud reporte unificado\": 0.016632899998512585,\n",
      "    \"Generaci\\u00f3n prompt + invocaci\\u00f3n LLM (reporte)\": 23.50188160000107\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Ejecutar Pruebas (Ejemplo) ---\n",
    "# Primero, asegúrate de haber ejecutado data_generator.py (o _light.py)\n",
    "# para que los archivos CSV, TXT y company_mapping.json existan.\n",
    "\n",
    "if not company_mapping:\n",
    "    print(\"No se pudo cargar el mapeo de empresas. Asegúrate de ejecutar el generador de datos primero.\")\n",
    "else:\n",
    "    test_company_data = company_mapping[0] # Tomamos la primera empresa del mapeo para la prueba de ejemplo\n",
    "    test_company_original_name = test_company_data[\"original_name\"]\n",
    "    test_company_sanitized_folder_name = test_company_data[\"sanitized_folder_name\"]\n",
    "\n",
    "    print(f\"\\nRealizando una prueba de ejemplo para la empresa: {test_company_original_name}\")\n",
    "    \n",
    "    if 'unified_report_1' in unified_report_prompts:\n",
    "        results = run_unified_report_flow(\n",
    "            company_original_name=test_company_original_name,\n",
    "            company_sanitized_folder_name=test_company_sanitized_folder_name,\n",
    "            report_prompt_key='unified_report_1',\n",
    "            user_query=\"Genera el resumen general de la empresa con los datos proporcionados.\"\n",
    "        )\n",
    "        print(\"\\n--- Resultados Detallados de la Prueba de Ejemplo ---\")\n",
    "        print(json.dumps(results, indent=2))\n",
    "    else:\n",
    "        print(\"El prompt 'unified_report_1' no está disponible en prompts.yml. Por favor, revisa tus prompts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a407fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando pruebas de estrés para 3 empresas...\n",
      "\n",
      "--- Ejecutando pruebas para la empresa: Muñoz LLC S.A.S. ---\n",
      "  > Con prompt: unified_report_1\n",
      "\n",
      "--- Ejecutando flujo para Muñoz LLC S.A.S. (unified_report_1) ---\n",
      "[TIMER] Normalización y decisión de flujo: 0.004s\n",
      "DEBUG_NORM: t_norm_result object: <utils.TimerResult object at 0x0000019E08CD0160>\n",
      "DEBUG_NORM: t_norm_result.elapsed_time: 0.0038657000040984713\n",
      "[TIMER] Inicialización cliente e historial: 0.022s\n",
      "DEBUG_INIT: t_init_result object: <utils.TimerResult object at 0x0000019E08CD3D90>\n",
      "DEBUG_INIT: t_init_result.elapsed_time: 0.022233600000618026\n",
      "[TIMER] Configuración y modelos: 0.058s\n",
      "DEBUG_CONFIG: t_config_result object: <utils.TimerResult object at 0x0000019E08CD1810>\n",
      "DEBUG_CONFIG: t_config_result.elapsed_time: 0.05843240000103833\n",
      "[TIMER] Carga documentos para empresa_1_Munoz_LLC_SAS: 0.002s\n",
      "[TIMER] Creación de PineconeManagers (carga de documentos): 0.002s\n",
      "DEBUG_PINECONE: t_pinecone_init_result object: <utils.TimerResult object at 0x0000019E08CD1510>\n",
      "DEBUG_PINECONE: t_pinecone_init_result.elapsed_time: 0.0020148000039625913\n",
      "[TIMER] Filtrado de dataframes por empresa (simulando query a BD): 0.003s\n",
      "DEBUG_FILTER: t_filter_df_result object: <utils.TimerResult object at 0x0000019E08CD0C10>\n",
      "DEBUG_FILTER: t_filter_df_result.elapsed_time: 0.002628599999297876\n",
      "[TIMER] Búsqueda similitud reporte unificado: 0.023s\n",
      "DEBUG_RAG: Tipo de t_rag_search_result después del bloque timer: <class 'utils.TimerResult'>\n",
      "DEBUG_RAG: Valor de t_rag_search_result.elapsed_time: 0.02283970000280533\n",
      "Respuesta del LLM generada (primeros 200 chars): # Unified Report 1: Muñoz LLC S.A.S.\n",
      "\n",
      "## 1. Descripción general de la empresa\n",
      "\n",
      "Muñoz LLC S.A.S. es una empresa que ha consolidado su presencia en el mercado delectus, experimentando un crecimiento del...\n",
      "[TIMER] Tiempo total conversación: 32.339s\n",
      "\n",
      "--- Métricas Finales para Muñoz LLC S.A.S. (unified_report_1) ---\n",
      "Tiempo Total de Ejecución: 32.339s\n",
      "Latencia de Invocación LLM (aislada): 32.220s\n",
      "Tokens de Entrada LLM: 1899\n",
      "Tokens de Salida LLM: 608\n",
      "Volumen de Transacciones procesadas: 84 filas\n",
      "Volumen de Financieros procesados: 48 filas\n",
      "Estado del flujo: success\n",
      "Tiempos por subproceso:\n",
      "  - Normalización y decisión de flujo: 0.004s\n",
      "  - Inicialización cliente e historial: 0.022s\n",
      "  - Configuración y modelos: 0.058s\n",
      "  - Creación de PineconeManagers (carga de documentos): 0.002s\n",
      "  - Filtrado de dataframes por empresa (simulando query a BD): 0.003s\n",
      "  - Búsqueda similitud reporte unificado: 0.023s\n",
      "  - Generación prompt + invocación LLM (reporte): 32.220s\n",
      "\n",
      "--- Ejecutando pruebas para la empresa: Posada-Peña S.A.S. ---\n",
      "  > Con prompt: unified_report_1\n",
      "\n",
      "--- Ejecutando flujo para Posada-Peña S.A.S. (unified_report_1) ---\n",
      "[TIMER] Normalización y decisión de flujo: 0.003s\n",
      "DEBUG_NORM: t_norm_result object: <utils.TimerResult object at 0x0000019E08CD16F0>\n",
      "DEBUG_NORM: t_norm_result.elapsed_time: 0.0026087999940500595\n",
      "[TIMER] Inicialización cliente e historial: 0.021s\n",
      "DEBUG_INIT: t_init_result object: <utils.TimerResult object at 0x0000019E08CD0400>\n",
      "DEBUG_INIT: t_init_result.elapsed_time: 0.02109059999929741\n",
      "[TIMER] Configuración y modelos: 0.053s\n",
      "DEBUG_CONFIG: t_config_result object: <utils.TimerResult object at 0x0000019E08CD0670>\n",
      "DEBUG_CONFIG: t_config_result.elapsed_time: 0.053297899998142384\n",
      "[TIMER] Carga documentos para empresa_2_Posada-Pena_SAS: 0.055s\n",
      "[TIMER] Creación de PineconeManagers (carga de documentos): 0.062s\n",
      "DEBUG_PINECONE: t_pinecone_init_result object: <utils.TimerResult object at 0x0000019E08CD0E50>\n",
      "DEBUG_PINECONE: t_pinecone_init_result.elapsed_time: 0.06227450000005774\n",
      "[TIMER] Filtrado de dataframes por empresa (simulando query a BD): 0.002s\n",
      "DEBUG_FILTER: t_filter_df_result object: <utils.TimerResult object at 0x0000019E08CD0C10>\n",
      "DEBUG_FILTER: t_filter_df_result.elapsed_time: 0.002097099997627083\n",
      "[TIMER] Búsqueda similitud reporte unificado: 0.010s\n",
      "DEBUG_RAG: Tipo de t_rag_search_result después del bloque timer: <class 'utils.TimerResult'>\n",
      "DEBUG_RAG: Valor de t_rag_search_result.elapsed_time: 0.009872900001937523\n",
      "Respuesta del LLM generada (primeros 200 chars): # Unified Report 1: Posada-Peña S.A.S.\n",
      "\n",
      "## 1. Descripción general de la empresa\n",
      "\n",
      "Posada-Peña S.A.S. es una empresa que ha consolidado su presencia en el mercado, experimentando un crecimiento del 5% e...\n",
      "[TIMER] Tiempo total conversación: 23.342s\n",
      "\n",
      "--- Métricas Finales para Posada-Peña S.A.S. (unified_report_1) ---\n",
      "Tiempo Total de Ejecución: 23.342s\n",
      "Latencia de Invocación LLM (aislada): 23.184s\n",
      "Tokens de Entrada LLM: 1917\n",
      "Tokens de Salida LLM: 443\n",
      "Volumen de Transacciones procesadas: 82 filas\n",
      "Volumen de Financieros procesados: 33 filas\n",
      "Estado del flujo: success\n",
      "Tiempos por subproceso:\n",
      "  - Normalización y decisión de flujo: 0.003s\n",
      "  - Inicialización cliente e historial: 0.021s\n",
      "  - Configuración y modelos: 0.053s\n",
      "  - Creación de PineconeManagers (carga de documentos): 0.062s\n",
      "  - Filtrado de dataframes por empresa (simulando query a BD): 0.002s\n",
      "  - Búsqueda similitud reporte unificado: 0.010s\n",
      "  - Generación prompt + invocación LLM (reporte): 23.184s\n",
      "\n",
      "--- Ejecutando pruebas para la empresa: González Inc S.A.S. ---\n",
      "  > Con prompt: unified_report_1\n",
      "\n",
      "--- Ejecutando flujo para González Inc S.A.S. (unified_report_1) ---\n",
      "[TIMER] Normalización y decisión de flujo: 0.004s\n",
      "DEBUG_NORM: t_norm_result object: <utils.TimerResult object at 0x0000019E08CD00D0>\n",
      "DEBUG_NORM: t_norm_result.elapsed_time: 0.004215900000417605\n",
      "[TIMER] Inicialización cliente e historial: 0.015s\n",
      "DEBUG_INIT: t_init_result object: <utils.TimerResult object at 0x0000019E08CD1360>\n",
      "DEBUG_INIT: t_init_result.elapsed_time: 0.01544080000167014\n",
      "[TIMER] Configuración y modelos: 0.059s\n",
      "DEBUG_CONFIG: t_config_result object: <utils.TimerResult object at 0x0000019E08CD13F0>\n",
      "DEBUG_CONFIG: t_config_result.elapsed_time: 0.05886129999998957\n",
      "[TIMER] Carga documentos para empresa_3_Gonzalez_Inc_SAS: 0.065s\n",
      "[TIMER] Creación de PineconeManagers (carga de documentos): 0.067s\n",
      "DEBUG_PINECONE: t_pinecone_init_result object: <utils.TimerResult object at 0x0000019E08CD1960>\n",
      "DEBUG_PINECONE: t_pinecone_init_result.elapsed_time: 0.06717000000207918\n",
      "[TIMER] Filtrado de dataframes por empresa (simulando query a BD): 0.004s\n",
      "DEBUG_FILTER: t_filter_df_result object: <utils.TimerResult object at 0x0000019E08CD3340>\n",
      "DEBUG_FILTER: t_filter_df_result.elapsed_time: 0.0035006000034627505\n",
      "[TIMER] Búsqueda similitud reporte unificado: 0.017s\n",
      "DEBUG_RAG: Tipo de t_rag_search_result después del bloque timer: <class 'utils.TimerResult'>\n",
      "DEBUG_RAG: Valor de t_rag_search_result.elapsed_time: 0.017144099998404272\n",
      "Respuesta del LLM generada (primeros 200 chars): # Unified Report 1: González Inc S.A.S.\n",
      "\n",
      "## 1. Descripción general de la empresa\n",
      "\n",
      "González Inc S.A.S. es una empresa consolidada en el sector de Tecnología y Servicios Financieros. En el último año, h...\n",
      "[TIMER] Tiempo total conversación: 29.823s\n",
      "\n",
      "--- Métricas Finales para González Inc S.A.S. (unified_report_1) ---\n",
      "Tiempo Total de Ejecución: 29.823s\n",
      "Latencia de Invocación LLM (aislada): 29.649s\n",
      "Tokens de Entrada LLM: 1882\n",
      "Tokens de Salida LLM: 601\n",
      "Volumen de Transacciones procesadas: 78 filas\n",
      "Volumen de Financieros procesados: 38 filas\n",
      "Estado del flujo: success\n",
      "Tiempos por subproceso:\n",
      "  - Normalización y decisión de flujo: 0.004s\n",
      "  - Inicialización cliente e historial: 0.015s\n",
      "  - Configuración y modelos: 0.059s\n",
      "  - Creación de PineconeManagers (carga de documentos): 0.067s\n",
      "  - Filtrado de dataframes por empresa (simulando query a BD): 0.004s\n",
      "  - Búsqueda similitud reporte unificado: 0.017s\n",
      "  - Generación prompt + invocación LLM (reporte): 29.649s\n",
      "\n",
      "--- Todas las pruebas de estrés ejecutadas ---\n",
      "Puedes analizar la variable 'all_test_results' para ver los resultados consolidados.\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Planificación de Pruebas de Estrés y Recopilación de Resultados ---\n",
    "\n",
    "# Este código te permite iterar sobre un subconjunto de empresas y diferentes prompts,\n",
    "# para recopilar métricas de rendimiento.\n",
    "\n",
    "all_test_results = []\n",
    "num_companies_to_test = min(3, len(company_mapping)) # Puedes ajustar cuántas empresas probar (ej: 5, 10, o len(company_mapping) para todas)\n",
    "\n",
    "print(f\"\\nIniciando pruebas de estrés para {num_companies_to_test} empresas...\")\n",
    "\n",
    "for i in range(num_companies_to_test):\n",
    "    company_data = company_mapping[i]\n",
    "    company_original_name = company_data[\"original_name\"]\n",
    "    company_sanitized_folder_name = company_data[\"sanitized_folder_name\"] # Esta variable ya contiene la carpeta simulada\n",
    "\n",
    "    print(f\"\\n--- Ejecutando pruebas para la empresa: {company_original_name} ---\")\n",
    "\n",
    "    # Puedes listar aquí los prompts que quieres probar.\n",
    "    # Por ejemplo, si tienes 'unified_report_1', 'unified_report_2', etc.\n",
    "    for prompt_key in ['unified_report_1']: # Empieza con uno o añade más como 'unified_report_2'\n",
    "        if prompt_key in unified_report_prompts:\n",
    "            print(f\"  > Con prompt: {prompt_key}\")\n",
    "            result = run_unified_report_flow(\n",
    "                company_original_name=company_original_name,\n",
    "                company_sanitized_folder_name=company_sanitized_folder_name,\n",
    "                report_prompt_key=prompt_key,\n",
    "                user_query=f\"Genera el reporte de {prompt_key} para {company_original_name}.\"\n",
    "            )\n",
    "            all_test_results.append({\n",
    "                \"company_name\": company_original_name,\n",
    "                \"prompt_key\": prompt_key,\n",
    "                \"metrics\": result\n",
    "            })\n",
    "        else:\n",
    "            print(f\"  > Advertencia: El prompt '{prompt_key}' no se encontró en unified_report_prompts. Saltando.\")\n",
    "\n",
    "# --- Análisis y Guardado de Resultados ---\n",
    "# Después de que todas las pruebas se ejecuten, 'all_test_results' contendrá un diccionario\n",
    "# con las métricas de cada corrida.\n",
    "\n",
    "print(\"\\n--- Todas las pruebas de estrés ejecutadas ---\")\n",
    "print(\"Puedes analizar la variable 'all_test_results' para ver los resultados consolidados.\")\n",
    "\n",
    "# Ejemplo de cómo podrías imprimir un resumen básico de los resultados:\n",
    "# for res in all_test_results:\n",
    "#     print(f\"\\nEmpresa: {res['company_name']}, Prompt: {res['prompt_key']}\")\n",
    "#     print(f\"  Estado: {res['metrics']['status']}\")\n",
    "#     print(f\"  Tiempo Total: {res['metrics']['total_execution_time']:.3f}s\")\n",
    "#     print(f\"  Latencia LLM: {res['metrics']['llm_api_latency']:.3f}s\")\n",
    "#     print(f\"  Tokens Entrada/Salida: {res['metrics']['llm_input_tokens']}/{res['metrics']['llm_output_tokens']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ad03c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company_name': 'Muñoz LLC S.A.S.',\n",
       " 'prompt_key': 'unified_report_1',\n",
       " 'metrics': {'status': 'success',\n",
       "  'total_execution_time': 32.339360099998885,\n",
       "  'llm_input_tokens': 1899,\n",
       "  'llm_output_tokens': 608,\n",
       "  'data_processed_tx_rows': 84,\n",
       "  'data_processed_fin_rows': 48,\n",
       "  'llm_api_latency': 32.22015090000059,\n",
       "  'timer_metrics': {'Normalización y decisión de flujo': 0.0038657000040984713,\n",
       "   'Inicialización cliente e historial': 0.022233600000618026,\n",
       "   'Configuración y modelos': 0.05843240000103833,\n",
       "   'Creación de PineconeManagers (carga de documentos)': 0.0020148000039625913,\n",
       "   'Filtrado de dataframes por empresa (simulando query a BD)': 0.002628599999297876,\n",
       "   'Búsqueda similitud reporte unificado': 0.02283970000280533,\n",
       "   'Generación prompt + invocación LLM (reporte)': 32.22015090000059}}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8068d99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company_name': 'Posada-Peña S.A.S.',\n",
       " 'prompt_key': 'unified_report_1',\n",
       " 'metrics': {'status': 'success',\n",
       "  'total_execution_time': 23.341757599999255,\n",
       "  'llm_input_tokens': 1917,\n",
       "  'llm_output_tokens': 443,\n",
       "  'data_processed_tx_rows': 82,\n",
       "  'data_processed_fin_rows': 33,\n",
       "  'llm_api_latency': 23.184409100002085,\n",
       "  'timer_metrics': {'Normalización y decisión de flujo': 0.0026087999940500595,\n",
       "   'Inicialización cliente e historial': 0.02109059999929741,\n",
       "   'Configuración y modelos': 0.053297899998142384,\n",
       "   'Creación de PineconeManagers (carga de documentos)': 0.06227450000005774,\n",
       "   'Filtrado de dataframes por empresa (simulando query a BD)': 0.002097099997627083,\n",
       "   'Búsqueda similitud reporte unificado': 0.009872900001937523,\n",
       "   'Generación prompt + invocación LLM (reporte)': 23.184409100002085}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "435870db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company_name': 'González Inc S.A.S.',\n",
       " 'prompt_key': 'unified_report_1',\n",
       " 'metrics': {'status': 'success',\n",
       "  'total_execution_time': 29.822612500000105,\n",
       "  'llm_input_tokens': 1882,\n",
       "  'llm_output_tokens': 601,\n",
       "  'data_processed_tx_rows': 78,\n",
       "  'data_processed_fin_rows': 38,\n",
       "  'llm_api_latency': 29.648700799996732,\n",
       "  'timer_metrics': {'Normalización y decisión de flujo': 0.004215900000417605,\n",
       "   'Inicialización cliente e historial': 0.01544080000167014,\n",
       "   'Configuración y modelos': 0.05886129999998957,\n",
       "   'Creación de PineconeManagers (carga de documentos)': 0.06717000000207918,\n",
       "   'Filtrado de dataframes por empresa (simulando query a BD)': 0.0035006000034627505,\n",
       "   'Búsqueda similitud reporte unificado': 0.017144099998404272,\n",
       "   'Generación prompt + invocación LLM (reporte)': 29.648700799996732}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_results[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f49dec",
   "metadata": {},
   "source": [
    "## Propuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "92cc296a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando credenciales de OpenAI...\n",
      "Credenciales cargadas. Cliente OpenAI inicializado.\n",
      "\n",
      "Cargando prompts desde prompts2.yml...\n",
      "[Carga de prompts y queries] Iniciando...\n",
      "Prompts de reporte unificado cargados: ['unified_report_1', 'unified_report_2', 'unified_report_3', 'unified_report_4', 'unified_report_5', 'hybrid_dynamic_update_prompt']\n",
      "[Carga de prompts y queries] Completado en 0.046 segundos.\n",
      "\n",
      "Cargando datas simuladas...\n",
      "[Carga de dataframes e historial] Iniciando...\n",
      "Data de transacciones cargada (LIGHT). Registros: 2000\n",
      "Data financiera cargada (LIGHT). Registros: 1000\n",
      "Mapeo de 25 empresas cargado.\n",
      "[Carga de dataframes e historial] Completado en 0.027 segundos.\n",
      "\n",
      "==================================================\n",
      "INICIANDO PRUEBAS DE ESTRÉS PARA 1 EMPRESAS\n",
      "==================================================\n",
      "\n",
      "************************************************************\n",
      "PROBANDO EMPRESA: Muñoz LLC S.A.S.\n",
      "************************************************************\n",
      "\n",
      "[FLUJO ORIGINAL] Iniciando generación de reporte unificado...\n",
      "\n",
      "--- Ejecutando flujo ORIGINAL para Muñoz LLC S.A.S. (unified_report_1) ---\n",
      "[Tiempo total conversación - ORIGINAL] Iniciando...\n",
      "[Normalización y decisión de flujo] Iniciando...\n",
      "[Normalización y decisión de flujo] Completado en 0.000 segundos.\n",
      "[Inicialización cliente e historial] Iniciando...\n",
      "[Inicialización cliente e historial] Completado en 0.000 segundos.\n",
      "[Configuración y modelos] Iniciando...\n",
      "[Configuración y modelos] Completado en 0.000 segundos.\n",
      "[Creación de PineconeManagers (carga de documentos)] Iniciando...\n",
      "[Carga documentos para empresa_1_Munoz_LLC_SAS] Iniciando...\n",
      "[Carga documentos para empresa_1_Munoz_LLC_SAS] Completado en 0.006 segundos.\n",
      "[Creación de PineconeManagers (carga de documentos)] Completado en 0.006 segundos.\n",
      "[Filtrado de dataframes por empresa (simulando query a BD)] Iniciando...\n",
      "[Filtrado de dataframes por empresa (simulando query a BD)] Completado en 0.007 segundos.\n",
      "[Búsqueda similitud reporte unificado] Iniciando...\n",
      "[Búsqueda similitud reporte unificado] Completado en 0.000 segundos.\n",
      "Respuesta del LLM generada (primeros 200 chars): 1. Descripción general de la empresa:\n",
      "\n",
      "Muñoz LLC S.A.S. es una empresa que ha consolidado su presencia en el mercado delectus, experimentando un crecimiento del 14% en sus operaciones en el último año...\n",
      "[Tiempo total conversación - ORIGINAL] Completado en 20.441 segundos.\n",
      "\n",
      "--- Métricas Finales para Muñoz LLC S.A.S. (unified_report_1) ---\n",
      "Tiempo Total de Ejecución: 20.441s\n",
      "Latencia de Invocación LLM (aislada): 20.421s\n",
      "Tokens de Entrada LLM: 1900\n",
      "Tokens de Salida LLM: 500\n",
      "Volumen de Transacciones procesadas: 84 filas\n",
      "Volumen de Financieros procesados: 48 filas\n",
      "Estado del flujo: success\n",
      "Tiempos por subproceso:\n",
      "   - Normalización y decisión de flujo: 0.000s\n",
      "   - Inicialización cliente e historial: 0.000s\n",
      "   - Configuración y modelos: 0.000s\n",
      "   - Creación de PineconeManagers (carga de documentos): 0.006s\n",
      "   - Filtrado de dataframes por empresa (simulando query a BD): 0.007s\n",
      "   - Búsqueda similitud reporte unificado: 0.000s\n",
      "   - Generación prompt + invocación LLM (reporte): 20.421s\n",
      "Resultado Flujo Original: Estado=success, Tiempo=20.441s\n",
      "\n",
      "[FLUJO HÍBRIDO] Iniciando actualización dinámica de reporte...\n",
      "\n",
      "--- Ejecutando flujo HÍBRIDO para Muñoz LLC S.A.S. con consulta: 'Genera el insight clave, oportunidad, priorización y frase sobre los nuevos datos de Muñoz LLC S.A.S..' ---\n",
      "[Tiempo total conversación - HÍBRIDA] Iniciando...\n",
      "[Carga de documentos estáticos para contexto (Híbrido)] Iniciando...\n",
      "[Carga documentos para empresa_1_Munoz_LLC_SAS] Iniciando...\n",
      "[Carga documentos para empresa_1_Munoz_LLC_SAS] Completado en 0.002 segundos.\n",
      "[Carga de documentos estáticos para contexto (Híbrido)] Completado en 0.003 segundos.\n",
      "[Consulta a BigQuery (simulada, nuevos datos para Híbrido)] Iniciando...\n",
      "  Simulando carga de BigQuery para versión: new_dynamic...\n",
      "[Consulta a BigQuery (simulada, nuevos datos para Híbrido)] Completado en 0.001 segundos.\n",
      "[Invocación LLM (Actualización Dinámica Híbrida)] Iniciando...\n",
      "[Invocación LLM (Actualización Dinámica Híbrida)] Completado en 2.725 segundos.\n",
      "Respuesta del LLM híbrida (primeros 200 chars): Lo siento, pero los nuevos datos proporcionados no contienen información sobre Muñoz LLC S.A.S., por lo tanto, no puedo generar un insight, una oportunidad, una priorización y una frase basadas en est...\n",
      "[Tiempo total conversación - HÍBRIDA] Completado en 2.731 segundos.\n",
      "\n",
      "--- Métricas Finales para Muñoz LLC S.A.S. (Flujo Híbrido) ---\n",
      "Tiempo Total de Ejecución: 2.731s\n",
      "Latencia de Invocación LLM (aislada): 2.725s\n",
      "Tokens de Entrada LLM: 1187\n",
      "Tokens de Salida LLM: 49\n",
      "Volumen de Transacciones procesadas: 2 filas\n",
      "Volumen de Financieros procesados: 1 filas\n",
      "Estado del flujo: success\n",
      "Tiempos por subproceso:\n",
      "   - Carga de documentos estáticos para contexto (Híbrido): 0.003s\n",
      "   - Consulta a BigQuery (simulada, nuevos datos para Híbrido): 0.001s\n",
      "   - Invocación LLM (Actualización Dinámica Híbrida): 2.725s\n",
      "Resultado Flujo Híbrido: Estado=success, Tiempo=2.731s\n",
      "\n",
      "==================================================\n",
      "RESUMEN DE RESULTADOS DE PRUEBAS DE ESTRÉS\n",
      "==================================================\n",
      "\n",
      "Resumen por tipo de flujo:\n",
      "| flow_type              | level_1                 |   metrics |\n",
      "|:-----------------------|:------------------------|----------:|\n",
      "| hybrid_dynamic_update  | total_execution_time    |     2.731 |\n",
      "| hybrid_dynamic_update  | llm_input_tokens        |  1187     |\n",
      "| hybrid_dynamic_update  | llm_output_tokens       |    49     |\n",
      "| hybrid_dynamic_update  | data_processed_tx_rows  |     2     |\n",
      "| hybrid_dynamic_update  | data_processed_fin_rows |     1     |\n",
      "| hybrid_dynamic_update  | llm_api_latency         |     2.725 |\n",
      "| initial_unified_report | total_execution_time    |    20.441 |\n",
      "| initial_unified_report | llm_input_tokens        |  1900     |\n",
      "| initial_unified_report | llm_output_tokens       |   500     |\n",
      "| initial_unified_report | data_processed_tx_rows  |    84     |\n",
      "| initial_unified_report | data_processed_fin_rows |    48     |\n",
      "| initial_unified_report | llm_api_latency         |    20.421 |\n",
      "\n",
      "Resultados detallados por empresa y flujo:\n",
      "\n",
      "--- Initial Unified Report para Muñoz LLC S.A.S. ---\n",
      "  Estado: success\n",
      "  Tiempo Total: 20.441s\n",
      "  Latencia LLM (aislada): 20.421s\n",
      "  Tokens In/Out: 1900/500\n",
      "  Filas TX/FIN: 84/48\n",
      "  Consulta: Genera un reporte unificado de oportunidades de negocio para Muñoz LLC S.A.S..\n",
      "\n",
      "--- Hybrid Dynamic Update para Muñoz LLC S.A.S. ---\n",
      "  Estado: success\n",
      "  Tiempo Total: 2.731s\n",
      "  Latencia LLM (aislada): 2.725s\n",
      "  Tokens In/Out: 1187/49\n",
      "  Filas TX/FIN: 2/1\n",
      "  Consulta: Genera el insight clave, oportunidad, priorización y frase sobre los nuevos datos de Muñoz LLC S.A.S..\n"
     ]
    }
   ],
   "source": [
    "# --- 0. Configuración Inicial y Carga de Librerías ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from contextlib import contextmanager # Necesario para el decorador @contextmanager\n",
    "\n",
    "# --- Definición de Timer (si utils.py no está en el PATH o por simplicidad) ---\n",
    "class TimerResult:\n",
    "    def __init__(self):\n",
    "        self.elapsed_time = 0.0\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    result = TimerResult()\n",
    "    result.start_time = time.perf_counter()\n",
    "    print(f\"[{name}] Iniciando...\")\n",
    "    try:\n",
    "        yield result\n",
    "    finally:\n",
    "        result.end_time = time.perf_counter()\n",
    "        result.elapsed_time = result.end_time - result.start_time\n",
    "        print(f\"[{name}] Completado en {result.elapsed_time:.3f} segundos.\")\n",
    "\n",
    "# >>>>> RUTA BASE PERSONALIZADA DEL PROYECTO (INTEGRACIÓN DE TU pk_) <<<<<\n",
    "pk_ = \"C:/Users/Alber/OneDrive/Documentos/MADUREZ MLOPS/gerente-relacional-qa-test/\"\n",
    "# Puedes ajustar esta variable si la ubicación de tu proyecto cambia.\n",
    "# >>>>> FIN DE RUTA BASE PERSONALIZADA <<<<<\n",
    "\n",
    "# --- 1. Cargar Credenciales ---\n",
    "print(\"Cargando credenciales de OpenAI...\")\n",
    "try:\n",
    "    # CORREGIDO: Asegurado el uso de pk_ para la ruta de credentials.json\n",
    "    with open(os.path.join('credentials.json')) as f:\n",
    "        config_env = json.load(f)\n",
    "    api_key = config_env[\"openai_key\"]\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    print(\"Credenciales cargadas. Cliente OpenAI inicializado.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: 'credentials.json' no encontrado en la ruta: {os.path.join(pk_, 'credentials.json')}. Asegúrate de crearlo en la raíz de tu proyecto ('{pk_}').\")\n",
    "    api_key = None\n",
    "    client = None\n",
    "except KeyError:\n",
    "    print(\"ERROR: 'openai_key' no encontrada en 'credentials.json'.\")\n",
    "    api_key = None\n",
    "    client = None\n",
    "\n",
    "# --- 2. Cargar Prompts del Reporte Unificado ---\n",
    "print(\"\\nCargando prompts desde prompts2.yml...\")\n",
    "# CORREGIDO: Asegurado el uso de pk_ para la ruta de prompts2.yml\n",
    "prompts_path = os.path.join('prompts2.yml')\n",
    "unified_report_prompts = {}\n",
    "with timer(\"Carga de prompts y queries\") as t_prompts:\n",
    "    try:\n",
    "        with open(prompts_path, 'r', encoding='utf-8') as file:\n",
    "            all_prompts = yaml.safe_load(file)\n",
    "        # Filtra los prompts relevantes\n",
    "        unified_report_prompts = {k: v for k, v in all_prompts.items() if k.startswith('unified_report_') or k.startswith('hybrid_dynamic_update_')}\n",
    "        print(f\"Prompts de reporte unificado cargados: {list(unified_report_prompts.keys())}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: '{prompts_path}' no encontrado.\")\n",
    "    except yaml.YAMLError as e:\n",
    "        print(f\"ERROR al parsear YAML: {e}\")\n",
    "\n",
    "# ### CAMBIO CRÍTICO PARA DEMO: DEFINICIÓN EXPLÍCITA DEL PROMPT HÍBRIDO ###\n",
    "# Esta es la definición del prompt que el usuario describió: toma el reporte pre-generado y lo actualiza.\n",
    "# Deberías copiar esto a tu prompts2.yml si lo apruebas.\n",
    "unified_report_prompts['hybrid_dynamic_update_prompt'] = \"\"\"\n",
    "Eres un asistente experto en finanzas.\n",
    "Has sido proporcionado con un reporte unificado pre-generado sobre la empresa {company_name}.\n",
    "Tu tarea es analizar este 'REPORTE PRE-GENERADO' en conjunto con los 'NUEVOS DATOS ACTUALIZADOS'.\n",
    "Basándote en este análisis, debes identificar y presentar de manera concisa:\n",
    "1.  **El insight clave** más relevante derivado de los nuevos datos y su impacto en el reporte pre-generado.\n",
    "2.  **Una oportunidad de negocio** prioritaria que surja de esta nueva información.\n",
    "3.  **Una priorización** clara de esta oportunidad o de las acciones a tomar.\n",
    "4.  **Una frase** concisa que capture la esencia de la actualización.\n",
    "\n",
    "Tu respuesta debe contener **ÚNICAMENTE estos cuatro puntos**, estructurados claramente, sin reescribir el reporte completo.\n",
    "\n",
    "--- REPORTE PRE-GENERADO ---\n",
    "{pre_generated_report}\n",
    "--- FIN REPORTE PRE-GENERADO ---\n",
    "\n",
    "--- RESÚMENES ORIGINALES DE CONTEXTO ---\n",
    "- Resumen de Gestión (Original): {management_report_summary}\n",
    "- Resumen Sectorial (Original): {sector_summary}\n",
    "- Resumen Financiero (Original): {financial_report_summary}\n",
    "--- FIN RESÚMENES ORIGINALES DE CONTEXTO ---\n",
    "\n",
    "--- NUEVOS DATOS ACTUALIZADOS DE BIGQUERY ---\n",
    "Datos de Desempeño y Pagos (Nuevos):\n",
    "{df_desem_pag_cast_md_new}\n",
    "Datos Perfilador Financiero (Nuevos):\n",
    "{df_perfilador_md_new}\n",
    "--- FIN NUEVOS DATOS ACTUALIZADOS ---\n",
    "\n",
    "Considerando la solicitud del usuario: \"{user_query}\"\n",
    "(Recuerda: Tu respuesta debe contener **ÚNICAMENTE** el insight, oportunidad, priorización y frase).\n",
    "\"\"\"\n",
    "# ### FIN CAMBIO CRÍTICO PARA DEMO ###\n",
    "\n",
    "# --- 3. Cargar Datas Simuladas (10M Transacciones y 300K Financieros) y Mapeo de Empresas ---\n",
    "print(\"\\nCargando datas simuladas...\")\n",
    "transactions_df = pd.DataFrame()\n",
    "financial_df = pd.DataFrame()\n",
    "company_mapping = [] # Lista de diccionarios {original_name, sanitized_folder_name}\n",
    "\n",
    "# Decide qué versión de datos cargar (LIGHT o FULL)\n",
    "USE_LIGHT_DATA = True # Cambia a False para usar los datos grandes (10M/300K)\n",
    "\n",
    "transactions_file = 'simulated_transactions.csv'\n",
    "financial_file = 'simulated_financial_metrics.csv'\n",
    "\n",
    "with timer(\"Carga de dataframes e historial\") as t_data_load:\n",
    "    try:\n",
    "        # Usar pk_ para la ruta de los archivos de datos\n",
    "        transactions_df = pd.read_csv(os.path.join(pk_, 'data', transactions_file))\n",
    "        print(f\"Data de transacciones cargada ({'LIGHT' if USE_LIGHT_DATA else 'FULL'}). Registros: {len(transactions_df)}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: '{transactions_file}' no encontrado en la ruta: '{os.path.join(pk_, 'data')}/'. Ejecuta data_generator.py (o _light.py).\")\n",
    "\n",
    "    try:\n",
    "        # Usar pk_ para la ruta de los archivos de datos\n",
    "        financial_df = pd.read_csv(os.path.join(pk_, 'data', financial_file))\n",
    "        print(f\"Data financiera cargada ({'LIGHT' if USE_LIGHT_DATA else 'FULL'}). Registros: {len(financial_df)}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: '{financial_file}' no encontrado en la ruta: '{os.path.join(pk_, 'data')}/'. Ejecuta data_generator.py (o _light.py).\")\n",
    "\n",
    "    # Cargar el mapeo de empresas\n",
    "    try:\n",
    "        # Usar pk_ para la ruta del mapeo de empresas\n",
    "        with open(os.path.join(pk_, 'data', 'company_mapping.json'), 'r', encoding='utf-8') as f:\n",
    "            company_mapping = json.load(f)\n",
    "        print(f\"Mapeo de {len(company_mapping)} empresas cargado.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: 'company_mapping.json' no encontrado en la ruta: '{os.path.join(pk_, 'data')}/'. Ejecuta data_generator.py (o _light.py).\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"ERROR: Fallo al leer 'company_mapping.json'. Asegúrate de que es un JSON válido.\")\n",
    "\n",
    "# --- 4. Función para Cargar Contenido de PDFs Simulados por Empresa (Tu versión adaptada) ---\n",
    "def load_company_documents(sanitized_folder_name):\n",
    "    \"\"\"Carga el contenido textual simulado de los PDFs para una empresa usando su nombre de carpeta sanitizado.\"\"\"\n",
    "    doc_contents = {}\n",
    "    # Usar pk_ para la ruta base de los documentos de las empresas\n",
    "    base_path = os.path.join(pk_, 'company_docs', sanitized_folder_name)\n",
    "    if not os.path.exists(base_path):\n",
    "        print(f\"Advertencia: Carpeta de documentos no encontrada para '{sanitized_folder_name}' en '{base_path}'\")\n",
    "        return doc_contents\n",
    "\n",
    "    with timer(f\"Carga documentos para {sanitized_folder_name}\") as t_doc_load:\n",
    "        for doc_type in ['gestion', 'sectorial', 'financiero']:\n",
    "            file_path = os.path.join(base_path, f'{doc_type}.txt')\n",
    "            if os.path.exists(file_path):\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    doc_contents[doc_type] = f.read()\n",
    "            else:\n",
    "                doc_contents[doc_type] = \"\" # Vacío si no se encuentra el archivo\n",
    "    return doc_contents\n",
    "\n",
    "# --- 5. Lógica Principal de Generación de Reporte (Emulación del main.py) ---\n",
    "# Esta función es la que quieres reutilizar para medir el tiempo \"completo\"\n",
    "def run_unified_report_flow(company_original_name, company_sanitized_folder_name, report_prompt_key, user_query=\"\"):\n",
    "    \"\"\"\n",
    "    Ejecuta un flujo simulado de generación de reporte unificado para una empresa.\n",
    "    Mide tiempos y recolecta métricas.\n",
    "    \"\"\"\n",
    "    # Asegúrate de que client, unified_report_prompts, company_mapping, transactions_df, financial_df\n",
    "    # estén definidos globalmente o pasados como argumentos.\n",
    "    if 'client' not in globals() or client is None or \\\n",
    "       'unified_report_prompts' not in globals() or not unified_report_prompts or \\\n",
    "       'company_mapping' not in globals() or not company_mapping or \\\n",
    "       'transactions_df' not in globals() or transactions_df.empty or \\\n",
    "       'financial_df' not in globals() or financial_df.empty:\n",
    "        print(\"ERROR: Variables globales (client, prompts, mapping, dataframes) no inicializadas. Abortando.\")\n",
    "        return {\"status\": \"failed\", \"error\": \"Setup incomplete\", \"generated_content\": \"ERROR\"}, \"ERROR\"\n",
    "\n",
    "    print(f\"\\n--- Ejecutando flujo ORIGINAL para {company_original_name} ({report_prompt_key}) ---\")\n",
    "    metrics = {\n",
    "        \"status\": \"success\",\n",
    "        \"total_execution_time\": 0.0,\n",
    "        \"llm_input_tokens\": 0,\n",
    "        \"llm_output_tokens\": 0,\n",
    "        \"data_processed_tx_rows\": 0,\n",
    "        \"data_processed_fin_rows\": 0,\n",
    "        \"llm_api_latency\": 0.0, # Latencia de la llamada al LLM aislada\n",
    "        \"timer_metrics\": {} # Para guardar los tiempos de cada [TIMER]\n",
    "    }\n",
    "    generated_content = \"\" # Inicializar para asegurar que siempre se retorne\n",
    "\n",
    "    with timer(\"Tiempo total conversación - ORIGINAL\") as total_timer_result:\n",
    "        with timer(\"Normalización y decisión de flujo\") as t_norm_result:\n",
    "            # time.sleep(0.001) # ### ELIMINADO time.sleep() ###\n",
    "            pass\n",
    "        metrics[\"timer_metrics\"][\"Normalización y decisión de flujo\"] = t_norm_result.elapsed_time\n",
    "        \n",
    "        with timer(\"Inicialización cliente e historial\") as t_init_result:\n",
    "            # time.sleep(0.01) # ### ELIMINADO time.sleep() ###\n",
    "            pass\n",
    "        metrics[\"timer_metrics\"][\"Inicialización cliente e historial\"] = t_init_result.elapsed_time\n",
    "\n",
    "        with timer(\"Configuración y modelos\") as t_config_result:\n",
    "            # time.sleep(0.05) # ### ELIMINADO time.sleep() ###\n",
    "            pass\n",
    "        metrics[\"timer_metrics\"][\"Configuración y modelos\"] = t_config_result.elapsed_time\n",
    "        \n",
    "        with timer(\"Creación de PineconeManagers (carga de documentos)\") as t_pinecone_init_result:\n",
    "            company_docs = load_company_documents(company_sanitized_folder_name)\n",
    "        metrics[\"timer_metrics\"][\"Creación de PineconeManagers (carga de documentos)\"] = t_pinecone_init_result.elapsed_time\n",
    "        \n",
    "        current_report_prompt_template = unified_report_prompts.get(report_prompt_key)\n",
    "        if not current_report_prompt_template:\n",
    "            print(f\"ERROR: Prompt '{report_prompt_key}' no encontrado.\")\n",
    "            metrics[\"status\"] = \"failed\"\n",
    "            metrics[\"error\"] = f\"Prompt '{report_prompt_key}' no encontrado.\"\n",
    "            return metrics, generated_content # Retornar también el contenido, incluso si es error\n",
    "        \n",
    "        with timer(\"Filtrado de dataframes por empresa (simulando query a BD)\") as t_filter_df_result:\n",
    "            company_transactions_df = transactions_df[transactions_df['company_name'] == company_original_name].copy()\n",
    "            company_financial_df = financial_df[financial_df['company_name'] == company_original_name].copy()\n",
    "            metrics[\"data_processed_tx_rows\"] = len(company_transactions_df)\n",
    "            metrics[\"data_processed_fin_rows\"] = len(company_financial_df)\n",
    "        metrics[\"timer_metrics\"][\"Filtrado de dataframes por empresa (simulando query a BD)\"] = t_filter_df_result.elapsed_time\n",
    "\n",
    "        with timer(\"Búsqueda similitud reporte unificado\") as t_rag_search_result:\n",
    "            context_from_docs = company_docs.get('gestion', '') + \"\\n\\n\" + \\\n",
    "                                company_docs.get('sectorial', '') + \"\\n\\n\" + \\\n",
    "                                company_docs.get('financiero', '')\n",
    "            # time.sleep(0.01 + len(context_from_docs) / 1000000.0) # Simulación de RAG ### ELIMINADO time.sleep() ###\n",
    "            pass\n",
    "        metrics[\"timer_metrics\"][\"Búsqueda similitud reporte unificado\"] = t_rag_search_result.elapsed_time\n",
    "\n",
    "        # Rellenar los placeholders del prompt\n",
    "        simulated_products_list = \"Préstamos Comerciales, Créditos de Liquidez, Cuentas de Ahorro, CDT.\"\n",
    "        simulated_sector = \"Tecnología y Servicios Financieros\" \n",
    "\n",
    "        df_desem_pag_cast_md_str = company_transactions_df.head(5).to_markdown(index=False)\n",
    "        df_perfilador_md_str = company_financial_df.head(5).to_markdown(index=False)\n",
    "\n",
    "        response_va_simulated = \"Según Valora Analitik, la empresa ha invertido en IA para optimizar procesos bancarios.\"\n",
    "        response_pp_simulated = \"En Primera Página se destacó la expansión regional de la empresa en el último año.\"\n",
    "\n",
    "        try:\n",
    "            formatted_prompt = current_report_prompt_template.format(\n",
    "                company_name=company_original_name,\n",
    "                user_request=user_query if user_query else f\"Genera un reporte unificado para {company_original_name} basado en los datos proporcionados.\",\n",
    "                management_report=company_docs.get('gestion', 'No disponible'),\n",
    "                sector=simulated_sector,\n",
    "                sector_report=company_docs.get('sectorial', 'No disponible'),\n",
    "                financial_report=company_docs.get('financiero', 'No disponible'),\n",
    "                response_va=response_va_simulated,\n",
    "                response_pp=response_pp_simulated,\n",
    "                df_desem_pag_cast_md=df_desem_pag_cast_md_str,\n",
    "                df_perfilador_md=df_perfilador_md_str,\n",
    "                products_list=simulated_products_list\n",
    "            )\n",
    "        except KeyError as e:\n",
    "            print(f\"ERROR: Placeholder '{e}' no encontrado en el prompt '{report_prompt_key}'. Revisa tu prompts.yml.\")\n",
    "            metrics[\"status\"] = \"failed\"\n",
    "            metrics[\"error\"] = f\"Placeholder '{e}' no encontrado.\"\n",
    "            return metrics, generated_content # Retornar también el contenido, incluso si es error\n",
    "\n",
    "        full_messages = [\n",
    "            {\"role\": \"system\", \"content\": formatted_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_query if user_query else f\"Genera el reporte unificado para {company_original_name}.\"}\n",
    "        ]\n",
    "\n",
    "        llm_invocation_start_time = time.perf_counter()\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-4\", # Usamos gpt-4\n",
    "                temperature=0.0,\n",
    "                messages=full_messages\n",
    "            )\n",
    "            metrics[\"llm_api_latency\"] = time.perf_counter() - llm_invocation_start_time\n",
    "            \n",
    "            generated_content = completion.choices[0].message.content\n",
    "            metrics[\"llm_input_tokens\"] = completion.usage.prompt_tokens\n",
    "            metrics[\"llm_output_tokens\"] = completion.usage.completion_tokens\n",
    "            \n",
    "            metrics[\"timer_metrics\"][\"Generación prompt + invocación LLM (reporte)\"] = metrics[\"llm_api_latency\"] \n",
    "            \n",
    "            print(f\"Respuesta del LLM generada (primeros 200 chars): {generated_content[:200]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR en invocación LLM: {e}\")\n",
    "            metrics[\"status\"] = \"failed\"\n",
    "            metrics[\"error\"] = str(e)\n",
    "            metrics[\"timer_metrics\"][\"Generación prompt + invocación LLM (reporte)\"] = time.perf_counter() - llm_invocation_start_time \n",
    "            generated_content = \"ERROR\" # Asegurar que 'generated_content' tenga un valor\n",
    "    \n",
    "    metrics[\"total_execution_time\"] = total_timer_result.elapsed_time\n",
    "\n",
    "    print(f\"\\n--- Métricas Finales para {company_original_name} ({report_prompt_key}) ---\")\n",
    "    print(f\"Tiempo Total de Ejecución: {metrics['total_execution_time']:.3f}s\")\n",
    "    print(f\"Latencia de Invocación LLM (aislada): {metrics['llm_api_latency']:.3f}s\")\n",
    "    print(f\"Tokens de Entrada LLM: {metrics['llm_input_tokens']}\")\n",
    "    print(f\"Tokens de Salida LLM: {metrics['llm_output_tokens']}\")\n",
    "    print(f\"Volumen de Transacciones procesadas: {metrics['data_processed_tx_rows']} filas\")\n",
    "    print(f\"Volumen de Financieros procesados: {metrics['data_processed_fin_rows']} filas\")\n",
    "    print(f\"Estado del flujo: {metrics['status']}\")\n",
    "    print(\"Tiempos por subproceso:\")\n",
    "    for k, v in metrics[\"timer_metrics\"].items():\n",
    "        if v is not None:\n",
    "            print(f\"   - {k}: {v:.3f}s\")\n",
    "        else:\n",
    "            print(f\"   - {k}: N/A (tiempo no capturado)\")\n",
    "\n",
    "    return metrics, generated_content # Ahora devuelve métricas y contenido generado\n",
    "\n",
    "# --- NUEVAS FUNCIONES Y SECCIÓN DE MEDICIONES (AGREGADO) ---\n",
    "\n",
    "# Mock de función para cargar \"nuevos datos\" de BigQuery.\n",
    "# Tu código original la llamaba, así que la definimos para evitar errores.\n",
    "# DEBES REEMPLAZAR ESTA LÓGICA SI TU ESCENARIO HÍBRIDO CARGA DATOS DIFERENTES.\n",
    "def load_simulated_bigquery_data(simulation_version=\"default\"):\n",
    "    \"\"\"\n",
    "    Simula la carga de datos de BigQuery.\n",
    "    En un escenario real, esto haría una consulta a tu BQ.\n",
    "    \"\"\"\n",
    "    print(f\"  Simulando carga de BigQuery para versión: {simulation_version}...\")\n",
    "    # time.sleep(0.1) # Simula una pequeña latencia ### ELIMINADO time.sleep() ###\n",
    "    if simulation_version == \"new_dynamic\":\n",
    "        # Datos ligeramente diferentes para simular \"nuevos\" datos\n",
    "        tx_data = {'company_name': ['CompanyA', 'CompanyA'], 'value': [105, 205]}\n",
    "        fin_data = {'company_name': ['CompanyA'], 'metric': [55.5]}\n",
    "    else:\n",
    "        # Usa los datos cargados globalmente como \"default\"\n",
    "        tx_data = transactions_df.head(2).to_dict('list') if not transactions_df.empty else {'company_name': [], 'value': []}\n",
    "        fin_data = financial_df.head(1).to_dict('list') if not financial_df.empty else {'company_name': [], 'metric': []}\n",
    "        \n",
    "    return pd.DataFrame(tx_data), pd.DataFrame(fin_data)\n",
    "\n",
    "# Función general para la invocación al LLM (para el flujo híbrido)\n",
    "# Asegura que capture tokens y latencia de manera similar a run_unified_report_flow\n",
    "def get_llm_response(prompt_messages, model=\"gpt-4\", temperature=0.5): \n",
    "    \"\"\"\n",
    "    Realiza la llamada al LLM y captura métricas.\n",
    "    'prompt_messages' debe ser una lista de diccionarios como [{'role': 'system', 'content': '...'}, {'role': 'user', 'content': '...'}]\n",
    "    \"\"\"\n",
    "    if client is None:\n",
    "        print(\"ERROR: Cliente OpenAI no inicializado en get_llm_response. No se puede invocar LLM.\")\n",
    "        return \"\", {\"status\": \"failed\", \"error\": \"LLM client not initialized\", \"llm_input_tokens\": 0, \"llm_output_tokens\": 0, \"llm_api_latency\": 0.0}\n",
    "\n",
    "    llm_invocation_start_time = time.perf_counter()\n",
    "    response_content = \"\"\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "    status = \"success\"\n",
    "    error_message = None\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            messages=prompt_messages\n",
    "        )\n",
    "        response_content = completion.choices[0].message.content\n",
    "        input_tokens = completion.usage.prompt_tokens\n",
    "        output_tokens = completion.usage.completion_tokens\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR en get_llm_response: {e}\")\n",
    "        status = \"failed\"\n",
    "        error_message = str(e)\n",
    "        response_content = \"ERROR EN LLM HÍBRIDO\" # Aseguramos un valor de retorno\n",
    "        \n",
    "    llm_api_latency = time.perf_counter() - llm_invocation_start_time\n",
    "    \n",
    "    metrics = {\n",
    "        \"status\": status,\n",
    "        \"error\": error_message,\n",
    "        \"llm_input_tokens\": input_tokens,\n",
    "        \"llm_output_tokens\": output_tokens,\n",
    "        \"llm_api_latency\": llm_api_latency,\n",
    "    }\n",
    "    return response_content, metrics\n",
    "\n",
    "# --- Función para el Flujo Híbrido Completo con Métricas ---\n",
    "def run_hybrid_update_flow(company_original_name, company_sanitized_folder_name, user_query, pre_generated_report_content=\"\"):\n",
    "    \"\"\"\n",
    "    Ejecuta el flujo de actualización híbrida y mide sus métricas.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Ejecutando flujo HÍBRIDO para {company_original_name} con consulta: '{user_query}' ---\")\n",
    "    \n",
    "    metrics = {\n",
    "        \"status\": \"success\",\n",
    "        \"total_execution_time\": 0.0,\n",
    "        \"llm_input_tokens\": 0,\n",
    "        \"llm_output_tokens\": 0,\n",
    "        \"data_processed_tx_rows\": 0,\n",
    "        \"data_processed_fin_rows\": 0,\n",
    "        \"llm_api_latency\": 0.0,\n",
    "        \"timer_metrics\": {}\n",
    "    }\n",
    "    generated_content = \"\"\n",
    "\n",
    "    with timer(\"Tiempo total conversación - HÍBRIDA\") as total_timer_result:\n",
    "        # Cargar los documentos estáticos para los resúmenes de contexto originales\n",
    "        with timer(\"Carga de documentos estáticos para contexto (Híbrido)\") as t_static_docs:\n",
    "            company_docs = load_company_documents(company_sanitized_folder_name)\n",
    "            # Volvemos a la lógica original de tomar los 200 primeros caracteres o el contenido completo si es corto\n",
    "            management_summary = company_docs.get('gestion', '')[:200] if len(company_docs.get('gestion', '')) > 200 else company_docs.get('gestion', '')\n",
    "            sector_summary = company_docs.get('sectorial', '')[:200] if len(company_docs.get('sectorial', '')) > 200 else company_docs.get('sectorial', '')\n",
    "            financial_summary = company_docs.get('financiero', '')[:200] if len(company_docs.get('financiero', '')) > 200 else company_docs.get('financiero', '')\n",
    "        metrics[\"timer_metrics\"][\"Carga de documentos estáticos para contexto (Híbrido)\"] = t_static_docs.elapsed_time\n",
    "        \n",
    "\n",
    "        # Simular la llegada de NUEVOS datos de BigQuery (valores cambiados)\n",
    "        with timer(\"Consulta a BigQuery (simulada, nuevos datos para Híbrido)\") as t_bigquery_fetch:\n",
    "            transactions_df_new_data, financial_df_new_data = load_simulated_bigquery_data(simulation_version=\"new_dynamic\")\n",
    "            metrics[\"data_processed_tx_rows\"] = len(transactions_df_new_data)\n",
    "            metrics[\"data_processed_fin_rows\"] = len(financial_df_new_data)\n",
    "        metrics[\"timer_metrics\"][\"Consulta a BigQuery (simulada, nuevos datos para Híbrido)\"] = t_bigquery_fetch.elapsed_time\n",
    "\n",
    "        df_desem_pag_cast_md_new_str = \"\"\n",
    "        if not transactions_df_new_data.empty:\n",
    "            df_desem_pag_cast_md_new_str = transactions_df_new_data.to_markdown(index=False) \n",
    "            \n",
    "        df_perfilador_md_new_str = \"\"\n",
    "        if not financial_df_new_data.empty:\n",
    "            df_perfilador_md_new_str = financial_df_new_data.to_markdown(index=False) \n",
    "\n",
    "        # Construir el PROMPT OPTIMIZADO para el LLM\n",
    "        optimized_prompt_template = unified_report_prompts.get('hybrid_dynamic_update_prompt')\n",
    "\n",
    "        if not optimized_prompt_template:\n",
    "            print(\"ERROR: El prompt 'hybrid_dynamic_update_prompt' no fue encontrado.\")\n",
    "            metrics[\"status\"] = \"failed\"\n",
    "            metrics[\"error\"] = \"Prompt 'hybrid_dynamic_update_prompt' no encontrado.\"\n",
    "            return metrics, generated_content\n",
    "        \n",
    "        try:\n",
    "            formatted_hybrid_prompt_text = optimized_prompt_template.format(\n",
    "                company_name=company_original_name,\n",
    "                pre_generated_report=pre_generated_report_content, # ¡Aquí pasamos el reporte completo pre-generado!\n",
    "                management_report_summary=management_summary, # Ahora son de los docs, truncados\n",
    "                sector_summary=sector_summary,                 # Ahora son de los docs, truncados\n",
    "                financial_report_summary=financial_summary,   # Ahora son de los docs, truncados\n",
    "                df_desem_pag_cast_md_new=df_desem_pag_cast_md_new_str,\n",
    "                df_perfilador_md_new=df_perfilador_md_new_str,\n",
    "                user_query=user_query\n",
    "            )\n",
    "        except KeyError as e:\n",
    "            print(f\"ERROR: Placeholder '{e}' no encontrado en el prompt optimizado. Revisa tu prompts.yml.\")\n",
    "            metrics[\"status\"] = \"failed\"\n",
    "            metrics[\"error\"] = f\"Placeholder '{e}' no encontrado en prompt híbrido.\"\n",
    "            return metrics, generated_content\n",
    "\n",
    "        # La llamada al LLM\n",
    "        hybrid_messages = [\n",
    "            {\"role\": \"system\", \"content\": formatted_hybrid_prompt_text},\n",
    "            {\"role\": \"user\", \"content\": user_query}\n",
    "        ]\n",
    "        \n",
    "        with timer(\"Invocación LLM (Actualización Dinámica Híbrida)\") as t_llm_hybrid:\n",
    "            generated_content, llm_metrics = get_llm_response(hybrid_messages, model=\"gpt-4\", temperature=0.5) \n",
    "\n",
    "        metrics[\"llm_api_latency\"] = llm_metrics[\"llm_api_latency\"]\n",
    "        metrics[\"llm_input_tokens\"] = llm_metrics[\"llm_input_tokens\"]\n",
    "        metrics[\"llm_output_tokens\"] = llm_metrics[\"llm_output_tokens\"]\n",
    "        metrics[\"status\"] = llm_metrics[\"status\"]\n",
    "        if llm_metrics[\"error\"]:\n",
    "            metrics[\"error\"] = llm_metrics[\"error\"]\n",
    "\n",
    "        metrics[\"timer_metrics\"][\"Invocación LLM (Actualización Dinámica Híbrida)\"] = t_llm_hybrid.elapsed_time\n",
    "\n",
    "        print(f\"Respuesta del LLM híbrida (primeros 200 chars): {generated_content[:200]}...\")\n",
    "        # NOTA: La vista previa puede ser corta porque ahora el output del LLM está diseñado para ser conciso.\n",
    "\n",
    "    metrics[\"total_execution_time\"] = total_timer_result.elapsed_time\n",
    "\n",
    "    print(f\"\\n--- Métricas Finales para {company_original_name} (Flujo Híbrido) ---\")\n",
    "    print(f\"Tiempo Total de Ejecución: {metrics['total_execution_time']:.3f}s\")\n",
    "    print(f\"Latencia de Invocación LLM (aislada): {metrics['llm_api_latency']:.3f}s\")\n",
    "    print(f\"Tokens de Entrada LLM: {metrics['llm_input_tokens']}\")\n",
    "    print(f\"Tokens de Salida LLM: {metrics['llm_output_tokens']}\")\n",
    "    print(f\"Volumen de Transacciones procesadas: {metrics['data_processed_tx_rows']} filas\")\n",
    "    print(f\"Volumen de Financieros procesados: {metrics['data_processed_fin_rows']} filas\")\n",
    "    print(f\"Estado del flujo: {metrics['status']}\")\n",
    "    print(\"Tiempos por subproceso:\")\n",
    "    for k, v in metrics[\"timer_metrics\"].items():\n",
    "        if v is not None:\n",
    "            print(f\"   - {k}: {v:.3f}s\")\n",
    "        else:\n",
    "            print(f\"   - {k}: N/A (tiempo no capturado)\")\n",
    "\n",
    "    return metrics, generated_content\n",
    "\n",
    "\n",
    "# --- SECCIÓN DE PRUEBAS DE ESTRÉS REAL ---\n",
    "\n",
    "all_test_results = []\n",
    "# Puedes ajustar cuántas empresas probar (ej: 1, 3, len(company_mapping) para todas)\n",
    "num_companies_to_test = min(len(company_mapping), 1) # Probamos solo 1 empresa para no consumir muchos tokens\n",
    "\n",
    "print(f\"\\n{'='*50}\\nINICIANDO PRUEBAS DE ESTRÉS PARA {num_companies_to_test} EMPRESAS\\n{'='*50}\")\n",
    "\n",
    "if not client:\n",
    "    print(\"El cliente OpenAI no está inicializado. Asegúrate de que las credenciales son correctas. Abortando pruebas de estrés.\")\n",
    "else:\n",
    "    for i in range(num_companies_to_test):\n",
    "        company_data = company_mapping[i]\n",
    "        company_original_name = company_data[\"original_name\"]\n",
    "        company_sanitized_folder_name = company_data[\"sanitized_folder_name\"]\n",
    "\n",
    "        print(f\"\\n{'*'*60}\\nPROBANDO EMPRESA: {company_original_name}\\n{'*'*60}\")\n",
    "\n",
    "        # --- PRUEBA 1: Generación del Reporte Unificado Inicial (Flujo Completo Original) ---\n",
    "        print(\"\\n[FLUJO ORIGINAL] Iniciando generación de reporte unificado...\")\n",
    "        initial_report_prompt_key = 'unified_report_1' # O el prompt que uses para el reporte inicial completo\n",
    "        user_query_initial = f\"Genera un reporte unificado de oportunidades de negocio para {company_original_name}.\"\n",
    "\n",
    "        if initial_report_prompt_key in unified_report_prompts:\n",
    "            initial_report_metrics, generated_initial_content = run_unified_report_flow(\n",
    "                company_original_name=company_original_name,\n",
    "                company_sanitized_folder_name=company_sanitized_folder_name,\n",
    "                report_prompt_key=initial_report_prompt_key,\n",
    "                user_query=user_query_initial\n",
    "            )\n",
    "            all_test_results.append({\n",
    "                \"flow_type\": \"initial_unified_report\",\n",
    "                \"company_name\": company_original_name,\n",
    "                \"prompt_key\": initial_report_prompt_key,\n",
    "                \"user_query\": user_query_initial,\n",
    "                \"metrics\": initial_report_metrics,\n",
    "                \"generated_content_preview\": generated_initial_content[:200] + \"...\" if generated_initial_content else \"\"\n",
    "            })\n",
    "            print(f\"Resultado Flujo Original: Estado={initial_report_metrics['status']}, Tiempo={initial_report_metrics['total_execution_time']:.3f}s\")\n",
    "        else:\n",
    "            print(f\"Advertencia: Prompt '{initial_report_prompt_key}' no encontrado. Saltando prueba de reporte unificado.\")\n",
    "            generated_initial_content = \"N/A\" # Para que el flujo híbrido no falle si el inicial se salta\n",
    "\n",
    "        # --- PRUEBA 2: Actualización Híbrida (Pre-generado + Actualización Dinámica) ---\n",
    "        if 'hybrid_dynamic_update_prompt' in unified_report_prompts:\n",
    "            print(\"\\n[FLUJO HÍBRIDO] Iniciando actualización dinámica de reporte...\")\n",
    "            user_query_hybrid = f\"Genera el insight clave, oportunidad, priorización y frase sobre los nuevos datos de {company_original_name}.\"\n",
    "            \n",
    "            hybrid_metrics, generated_hybrid_content = run_hybrid_update_flow(\n",
    "                company_original_name=company_original_name,\n",
    "                company_sanitized_folder_name=company_sanitized_folder_name,\n",
    "                user_query=user_query_hybrid,\n",
    "                pre_generated_report_content=generated_initial_content # Pasamos el contenido generado por el flujo inicial\n",
    "            )\n",
    "            all_test_results.append({\n",
    "                \"flow_type\": \"hybrid_dynamic_update\",\n",
    "                \"company_name\": company_original_name,\n",
    "                \"prompt_key\": 'hybrid_dynamic_update_prompt',\n",
    "                \"user_query\": user_query_hybrid,\n",
    "                \"metrics\": hybrid_metrics,\n",
    "                \"generated_content_preview\": generated_hybrid_content[:200] + \"...\" if generated_hybrid_content else \"\"\n",
    "            })\n",
    "            print(f\"Resultado Flujo Híbrido: Estado={hybrid_metrics['status']}, Tiempo={hybrid_metrics['total_execution_time']:.3f}s\")\n",
    "        else:\n",
    "            print(f\"Advertencia: Prompt 'hybrid_dynamic_update_prompt' no encontrado. Saltando prueba de flujo híbrido.\")\n",
    "\n",
    "\n",
    "# --- Análisis de Resultados Globales ---\n",
    "print(f\"\\n{'='*50}\\nRESUMEN DE RESULTADOS DE PRUEBAS DE ESTRÉS\\n{'='*50}\")\n",
    "\n",
    "if all_test_results:\n",
    "    df_results = pd.DataFrame(all_test_results)\n",
    "    \n",
    "    # Resumen general\n",
    "    print(\"\\nResumen por tipo de flujo:\")\n",
    "    summary_by_flow = df_results.groupby('flow_type')['metrics'].apply(lambda x: pd.DataFrame(list(x)).mean(numeric_only=True)).reset_index()\n",
    "    print(summary_by_flow.round(3).to_markdown(index=False))\n",
    "\n",
    "    print(\"\\nResultados detallados por empresa y flujo:\")\n",
    "    for result in all_test_results:\n",
    "        print(f\"\\n--- {result['flow_type'].replace('_', ' ').title()} para {result['company_name']} ---\")\n",
    "        print(f\"  Estado: {result['metrics']['status']}\")\n",
    "        print(f\"  Tiempo Total: {result['metrics']['total_execution_time']:.3f}s\")\n",
    "        print(f\"  Latencia LLM (aislada): {result['metrics']['llm_api_latency']:.3f}s\")\n",
    "        print(f\"  Tokens In/Out: {result['metrics']['llm_input_tokens']}/{result['metrics']['llm_output_tokens']}\")\n",
    "        print(f\"  Filas TX/FIN: {result['metrics']['data_processed_tx_rows']}/{result['metrics']['data_processed_fin_rows']}\")\n",
    "        if 'user_query' in result:\n",
    "            print(f\"  Consulta: {result['user_query']}\")\n",
    "        # Puedes añadir más detalles si es necesario\n",
    "else:\n",
    "    print(\"No se generaron resultados de pruebas. Revisa los mensajes de error anteriores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8148bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
